{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ccc0c2-caf8-4231-8f7f-d898ad92d57c",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc4e309-4eef-4ce8-8f11-55010484fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "BASE_PATH =  \"/Users/audreymcmillion/Documents/acm-thesis\"\n",
    "sys.path.append(BASE_PATH) \n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "from model_fitting import ModelFitting\n",
    "from ev_scoring import ExtremeValueScoring\n",
    "from market_utils import MarketUtilities\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "\n",
    "ev = ExtremeValueScoring(wrds_username='audreymcmillion')\n",
    "db = ev.wrds_db\n",
    "conn = ev.sqlite_conn\n",
    "mkt_utils = MarketUtilities(wrds_username='audreymcmillion', wrds_db = db, sqlite_conn = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac982560-17c0-4b94-b833-ae3e17245a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_models(df, name_col = \"model\"):\n",
    "    # Get unique models and categorize\n",
    "    model_names = sorted(df[name_col].unique().tolist(), reverse=True)\n",
    "    gamma_models = [m for m in model_names if \"gamma\" in m.lower()]\n",
    "    residual_models = [m for m in model_names if \"residual\" in m.lower()]\n",
    "    garch_models = [m for m in model_names if \"ar(1)-garch(1,1)\" in m.lower() and m not in gamma_models and m not in residual_models]\n",
    "    other_models = [m for m in model_names if m not in gamma_models + residual_models + garch_models]\n",
    "\n",
    "    # Build ordered list\n",
    "    ordered_models = gamma_models + residual_models + garch_models + other_models\n",
    "    return ordered_models, (gamma_models, residual_models, garch_models, other_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d36c5f6-1f57-4b30-85d0-a6feea427ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_shift_query = \"\"\"\n",
    "    SELECT \n",
    "        t.*,\n",
    "        ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY chunk_end_date) AS rn\n",
    "    FROM iterative_ev_kl_5D t\n",
    "    WHERE chunk_start_date > '2000-01-01'\n",
    "    AND kl_divergence > 0.5\n",
    "    AND chunk_end_date > '2020-01-31'\n",
    "  \"\"\"\n",
    "ex_distshift_df = pd.read_sql(dist_shift_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0984f36-f7ae-4a91-8536-17707d088b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_distshift_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1eaae-f936-4fb5-8b2e-83e1d7f3fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "eval_template = \"\"\"\n",
    "    with garch_vals as (\n",
    "    \tselect symbol, test_set, model, count(*) as garch_count\n",
    "    \tfrom argarch_results ar \n",
    "    \twhere model = 'AR(1)-GARCH(1,1)'\n",
    "    \tgroup by 1, 2, 3\n",
    "    \tHAVING count(*) >= 100\n",
    "    ),\n",
    "    \n",
    "    dtaci_vals as (\n",
    "    \tSELECT symbol, conformity_score, test_set, model, count(*) as dtaci_count\n",
    "    \tfrom dtaci_results_new drn \n",
    "    \twhere conformity_score = 'residual_normalized'\n",
    "    \tand model =  'AR(1)-GARCH(1,1)'\n",
    "    \tgroup by 1, 2, 3, 4\n",
    "    \tHAVING count(*) >= 100\n",
    "    ),\n",
    "    \n",
    "    common_records as (\n",
    "    \tSELECT gv.symbol\n",
    "    \tFROM garch_vals gv\n",
    "    \tjoin dtaci_vals dv\n",
    "    \twhere (gv.symbol, gv.test_set) = (dv.symbol, dv.test_set)\n",
    "    )\n",
    "    \n",
    "    select * \n",
    "    from model_coverage_stats2\n",
    "    where test_set = '{test_set}'\n",
    "    and (model = 'AR(1)-GARCH(1,1)' or base_model in ('AR(1)-GARCH(1,1)', 'AR(1)')) \n",
    "    and symbol in (select distinct symbol from common_records)\n",
    "    order by model\n",
    "    \"\"\"\n",
    "\n",
    "def break_label(label):\n",
    "    parts = label.split()\n",
    "    if len(parts) > 2:\n",
    "        return \" \".join(parts[:2]) + \"<br>\" + \" \".join(parts[2:])\n",
    "    else:\n",
    "        return label\n",
    "\n",
    "def get_data(test_set):\n",
    "    if test_set == 'Real Distribution Shift (in Extreme)':\n",
    "        df = pd.read_sql(eval_template.format(test_set='Real Distribution Shift'), conn)\n",
    "        dist_shift_query = \"\"\"\n",
    "            SELECT \n",
    "                t.*,\n",
    "                ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY chunk_end_date) AS rn\n",
    "            FROM iterative_ev_kl_5D t\n",
    "            WHERE chunk_start_date > '2000-01-01'\n",
    "            AND kl_divergence > 0.5\n",
    "            AND chunk_end_date > '2020-01-31'\n",
    "          \"\"\"\n",
    "        ex_distshift_df = pd.read_sql(dist_shift_query, conn)\n",
    "        ex_symbols = list(ex_distshift_df[\"symbol\"].unique())\n",
    "        return df[df['symbol'].isin(ex_symbols)] #.reset_index(drop=True)\n",
    "    else:\n",
    "         df = pd.read_sql(eval_template.format(test_set=test_set), conn)\n",
    "         return df\n",
    "\n",
    "def to_rgb_tuple(color_str):\n",
    "    \"\"\"Convert Plotly color string (hex or 'rgb(...)') to RGB tuple.\"\"\"\n",
    "    if color_str.startswith(\"rgb\"):\n",
    "        nums = color_str.strip(\"rgb()\").split(\",\")\n",
    "        return tuple(int(n) / 255 for n in nums)\n",
    "    else:\n",
    "        return mcolors.to_rgb(color_str)\n",
    "        \n",
    "def darken_palette(palette, factor=0.85):\n",
    "    darkened = []\n",
    "    for color_str in palette:\n",
    "        rgb = to_rgb_tuple(color_str)\n",
    "        dark_rgb = tuple(max(0, c * factor) for c in rgb)\n",
    "        darkened.append(mcolors.to_hex(dark_rgb))\n",
    "    return darkened\n",
    "\n",
    "def create_boxplots(\n",
    "    test_set: str,\n",
    "    x_columns=[\"coverage\", \"avg_width\", \"mwi_score\", \"cwc_score\"],\n",
    "    eval_template=eval_template\n",
    "):\n",
    "    df = get_data(test_set)\n",
    "        \n",
    "    df_display = df.copy()\n",
    "    df_display[\"model_wrapped\"] = df_display[\"model\"].apply(break_label)\n",
    "\n",
    "    # Build ordered list\n",
    "    ordered_models, components = get_ordered_models(df_display)\n",
    "    gamma_models, residual_models, garch_models, other_models = components\n",
    "\n",
    "    # Color maps\n",
    "    blue_palette = px.colors.sequential.Blues[1::2][1:]\n",
    "    green_palette = px.colors.sequential.Greens[1:]\n",
    "    # green_palette = darken_palette(green_palette, factor=0.9)\n",
    "    \n",
    "    color_map = {}\n",
    "    for i, m in enumerate(gamma_models):\n",
    "        color_map[m] = blue_palette[i]\n",
    "    for i, m in enumerate(residual_models):\n",
    "        if \"DtACI\" in m:\n",
    "            color_map[m] = green_palette[i]\n",
    "    for m in garch_models:\n",
    "        color_map[m] = \"darkred\"\n",
    "\n",
    "    color_map['OC: Residual Normalized Score'] = '#CC5500'\n",
    "    color_map['NC: Residual Normalized Score'] = '#FFD580'\n",
    "\n",
    "\n",
    "    # Define pretty subplot titles and corresponding x-axis labels\n",
    "    subplot_labels = {\n",
    "        \"coverage\": \"Coverage\",\n",
    "        \"avg_width\": \"√(Average Width)\",\n",
    "        \"mwi_score\": \"√(MWI Score)\",\n",
    "        \"cwc_score\": \"√(CWC)\"\n",
    "    }\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=len(x_columns),\n",
    "        shared_yaxes=True,\n",
    "        subplot_titles=[subplot_labels.get(c, c) for c in x_columns]\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    for i, x_col in enumerate(x_columns, start=1):\n",
    "        for m in ordered_models:\n",
    "            #if \"Gamma\" in m:\n",
    "            #    continue\n",
    "\n",
    "            temp = df_display[df_display[\"model\"] == m]\n",
    "            if temp.empty:\n",
    "                continue\n",
    "\n",
    "            color = color_map.get(m, \"gray\")\n",
    "            x_data = np.sqrt(temp[x_col]) if x_col != \"coverage\" else temp[x_col]\n",
    "\n",
    "            trace = go.Box(\n",
    "                x=x_data,\n",
    "                y=temp[\"model_wrapped\"],\n",
    "                name=m,\n",
    "                orientation=\"h\",\n",
    "                boxmean=True,\n",
    "                boxpoints=False,\n",
    "                marker=dict(color=color),\n",
    "                showlegend=False\n",
    "            )\n",
    "\n",
    "            fig.add_trace(trace, row=1, col=i)\n",
    "\n",
    "        # Set individual x-axis titles\n",
    "        fig.update_xaxes(title_text=subplot_labels.get(x_col, x_col), row=1, col=i)\n",
    "\n",
    "    # Consistent formatting across all subplots\n",
    "    for i in range(1, len(x_columns) + 1):\n",
    "        fig.update_xaxes(tickformat=\",.2f\", row=1, col=i)\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        showlegend=False,\n",
    "        title_text=f\"Boxplots per Model and Metric for {test_set} Test Set\",\n",
    "        template=\"ggplot2\",\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131d65c-c419-483b-9465-dda37bbe018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplots(\"Real Distribution Shift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1094bd41-3f0a-4c86-9516-27a20eb013be",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplots(\"Real Distribution Shift (in Extreme)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7354a2-b1bd-415e-ba80-c221c3abc27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplots(\"Real Anomaly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d165f-644b-4da3-921c-1101085dd97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplots(\"Simulated Distribution Shift 700\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a6d59-9637-422b-abb9-01fc7272c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplots(\"Simulated Anomaly 700\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b4ad6-822b-4d0e-a0e4-f725e7d10f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplots(\"Simulated DistShift+Anom 700\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5658a73-cc5b-47a8-95c1-c376815d146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "\n",
    "test_set = \"Simulated DistShift+Anom 700\"\n",
    "df = pd.read_sql(eval_template.format(test_set=test_set), conn)\n",
    "\n",
    "# Extract std category from symbol, e.g. \"AAPL|std=5;6\" → \"5;6\"\n",
    "df[\"std_category\"] = df[\"symbol\"].str.extract(r\"\\|std=(.*)$\")\n",
    "\n",
    "# Group by std_category and model, then compute medians\n",
    "agg_df = (\n",
    "    df.groupby([\"std_category\", \"model\"], as_index=False)\n",
    "    .agg({\n",
    "        \"avg_width\": \"median\",\n",
    "        \"cwc_score\": \"median\",\n",
    "        \"mwi_score\": \"median\",\n",
    "        \"coverage\": \"mean\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "agg_df.rename(columns={\n",
    "    \"avg_width\": \"median_avg_width\",\n",
    "    \"cwc_score\": \"median_cwc_score\",\n",
    "    \"mwi_score\": \"median_mwi_score\",\n",
    "    \"coverage\": \"average_coverage\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Display or save the result\n",
    "agg_df\n",
    "#Create a pivot table\n",
    "pivot_table = pd.pivot_table(agg_df, values=['median_avg_width', 'median_cwc_score', 'median_mwi_score', 'average_coverage'], \n",
    "                             index='std_category', columns='model', aggfunc=np.sum, fill_value=0)\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3132aa55-4f63-4888-86db-889b5ca56b49",
   "metadata": {},
   "source": [
    "## Smaller Sample Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1d6f5-f6bb-40d1-94b0-56339bd2f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_template_small = \"\"\"\n",
    "    select * \n",
    "    from model_coverage_stats\n",
    "    where test_set = '{test_set}'\n",
    "    and (model = 'AR(1)-ARCH(1)' or base_model in ('AR(1)-ARCH(1) - 200', 'AR(1) - 200')) \n",
    "    and symbol in (\n",
    "        select distinct symbol\n",
    "    from argarch_results ar \n",
    "    where test_set = '{test_set}'\n",
    "    group by symbol\n",
    "    having count(*) >= 100\n",
    "    )\n",
    "    order by model\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a167d3-f9e7-4143-b013-2b3476bc7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplots(test_set=\"Simulated Distribution Shift 700\", \n",
    "                x_columns=[\"median_width\", \"mwi_score\", \"cwc_score\", \"coverage\"], eval_template = eval_template_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d20931-4640-45b4-b0af-e2596e1e4450",
   "metadata": {},
   "source": [
    "## Visualizing bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14895ee-deb3-46ee-b121-7580d383bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_forecast(forecast_df, level=0.95):\n",
    "    # Set the target coverage level\n",
    "    target_coverage = level * 100\n",
    "\n",
    "    # Identify points outside the confidence interval\n",
    "    out_of_band = (forecast_df['actual'] < forecast_df['lower_bound']) | (forecast_df['actual'] > forecast_df['upper_bound'])\n",
    "    \n",
    "    # Compute empirical coverage\n",
    "    coverage = 1 - out_of_band.mean()\n",
    "    coverage_percent = coverage * 100\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 3.7))\n",
    "    plt.grid(axis='y', linestyle='--', linewidth=0.5, color='lightgrey', zorder=0)\n",
    "    plt.plot(forecast_df['actual'], label='Actual Return', color='black', alpha=0.7)\n",
    "    plt.plot(forecast_df['forecast'], label='Forecasted Mean', color='orange', linestyle='--')\n",
    "    plt.fill_between(\n",
    "        forecast_df.index,\n",
    "        forecast_df['lower_bound'],\n",
    "        forecast_df['upper_bound'],\n",
    "        color='orange',\n",
    "        alpha=0.2,\n",
    "        label=f'{target_coverage:.1f}% CI'\n",
    "    )\n",
    "\n",
    "    # Add red dots for out-of-band points\n",
    "    plt.scatter(\n",
    "        forecast_df.index[out_of_band],\n",
    "        forecast_df['actual'][out_of_band],\n",
    "        color='red',\n",
    "        label='Outside Bands',\n",
    "        zorder=5\n",
    "    )\n",
    "\n",
    "    # Add coverage text (top-left corner)\n",
    "    plt.text(\n",
    "        0.01, 0.98,\n",
    "        f'Empirical coverage: {coverage_percent:.2f}%',\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment='top',\n",
    "        horizontalalignment='left',\n",
    "       # bbox=dict(facecolor='white', alpha=0.6, edgecolor='none')\n",
    "    )\n",
    "\n",
    "    # Identify min(lower_bound) and max(upper_bound)\n",
    "    lb_min_idx = forecast_df['lower_bound'].idxmin()\n",
    "    lb_min_val = forecast_df['lower_bound'].min()\n",
    "    \n",
    "    ub_max_idx = forecast_df['upper_bound'].idxmax()\n",
    "    ub_max_val = forecast_df['upper_bound'].max()\n",
    "    \n",
    "    # Annotate min lower bound\n",
    "    plt.scatter(lb_min_idx, lb_min_val, color='blue', zorder=4)\n",
    "    plt.text(\n",
    "        lb_min_idx, lb_min_val,\n",
    "        f'  Min LB: {lb_min_val:.4f}',\n",
    "        va='bottom', ha='left', fontsize=9\n",
    "    )\n",
    "    \n",
    "    # Annotate max upper bound\n",
    "    plt.scatter(ub_max_idx, ub_max_val, color='blue', zorder=4)\n",
    "    plt.text(\n",
    "        ub_max_idx, ub_max_val,\n",
    "        f'  Max UB: {ub_max_val:.4f}',\n",
    "        va='bottom', ha='left', fontsize=9\n",
    "    )\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # Titles and legend\n",
    "    plt.title(f'One-Step-Ahead Forecast with {target_coverage:.1f}% Confidence Interval')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420004e1-6e5a-4e8f-8932-285cd04c27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_sql(\"select * from model_coverage_stats where test_set = 'Real Distribution Shift' and model not like '%Gamma%'\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1495584-7445-4853-ac1d-7c41ae89e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(\"avg_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e32b968-994b-473a-bc29-37adba5257b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_anom = get_data(\"Real Anomaly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0146a9d5-b77a-4a46-8d21-531135f5460c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_anom[[\"symbol\", \"start_dt\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2be4be-30d6-4543-aea0-b60bf85e71c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df_1 = pd.read_sql(\"\"\"\n",
    "select * \n",
    "from argarch_results \n",
    "where symbol = 'FTSM'\n",
    "and test_set = 'Real Distribution Shift' \n",
    "and model = 'AR(1)-GARCH(1,1)'\"\"\", \n",
    "                            conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4dfab-a918-418e-a6bc-bd5d2e03e83c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecast_df_1 #.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f70823-b0fa-49ef-9fc1-8f90f6aba4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(forecast_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f9ae3-3a1a-4997-8322-ef259656da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df_2 = pd.read_sql(\"\"\"\n",
    "select * \n",
    "from dtaci_results_new\n",
    "where symbol = 'FTSM' --'628432101714|std=6;7' \n",
    "and model = 'AR(1)-GARCH(1,1);I=150'\n",
    "and conformity_score = 'residual_normalized'\n",
    "and test_set = 'Real Distribution Shift'\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc2608-5f54-4ee7-b374-bbaeddd7c746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecast_df_2.sort_values(\"upper_bound\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb651502-ff21-4696-b62f-9815e17c7682",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(forecast_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9bf7f-437c-4931-885d-a4949b00bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df_3 = pd.read_sql(\"\"\"\n",
    "select * \n",
    "from argarch_results\n",
    "where symbol = '126084872733' --'628432101714|std=6;7' \n",
    "and model = 'AR(1)-GARCH(1,1)'\n",
    "and test_set = 'Simulated Distribution Shift 700'\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20c5729-ebd7-465c-9295-b685bb97adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(forecast_df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede78ac6-2450-4f93-aa2f-7eea9c498e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "forecast_df_1['band_width'] = forecast_df_1['upper_bound'] - forecast_df_1['lower_bound'] \n",
    "forecast_df_2['band_width'] = forecast_df_2['upper_bound'] - forecast_df_2['lower_bound']\n",
    "\n",
    "# Slice from index 74 onward\n",
    "band_width_1 = forecast_df_1['band_width'].iloc[75:100]\n",
    "band_width_2 = forecast_df_2['band_width'].iloc[75:100]\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(5, 7))\n",
    "plt.grid(axis='y', linestyle='--', linewidth=0.5, color='lightgrey', zorder=0)\n",
    "plt.plot(band_width_1.index, band_width_1, marker='o', label='AR(1)-GARCH(1,1)', color='blue')\n",
    "plt.plot(band_width_2.index, band_width_2, marker='o', label='DtACI', color='orange')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Band Width')\n",
    "plt.title('Comparison of Band Width per Model\\nfollowing Anomaly at Index = 74 (USEG)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623ca71-4509-47b7-93df-76ad74c30209",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df_1[forecast_df_1.within_CI != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0a926-cd5c-48fc-bd03-69e9e285b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df_3= pd.read_sql(\"\"\"\n",
    "select * \n",
    "from conformal_results\n",
    "where symbol = 'USEG' \n",
    "and conformal_mode = 'naive'\n",
    "and base_model = 'AR(1)-GARCH(1,1)'\n",
    "and conformity_score = 'residual_normalized'\n",
    "and test_set = 'Real Anomaly'\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f0a92-5ccf-4531-836b-5364e3fcd0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6688d-c121-4d95-bc11-2256b7332557",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(forecast_df_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d24b40-725d-47b3-a5cb-1fdfce9efcf7",
   "metadata": {},
   "source": [
    "## Distribution Shift Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960e60f-18e5-4200-b12d-9580df094f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "czr_dist_shift = pd.read_sql(\"\"\"\n",
    "select ev.*, kl.kl_divergence\n",
    "from iterative_extreme_values ev\n",
    "left join iterative_ev_kl_5D kl\n",
    "on (ev.symbol, ev.chunk_start_date, ev.chunk_end_date) = (kl.symbol, kl.chunk_start_date, kl.chunk_end_date)\n",
    "where ev.symbol = 'CZR'\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80fe096-db58-44db-ada7-50bd119df0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "czr_dist_shift[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3956f9f-85e0-41d3-913d-00f033800f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import genextreme\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Use a colormap for different colors\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(czr_dist_shift[-5:])))\n",
    "\n",
    "for i, (ind, row) in enumerate(czr_dist_shift[-5:].iterrows()):\n",
    "    c = row['parameters_c']\n",
    "    loc = row['parameters_loc']\n",
    "    scale = row['parameters_scale']\n",
    "\n",
    "    # Generate x-values safely within distribution support\n",
    "    x = np.linspace(\n",
    "        genextreme.ppf(0.01, c, loc=loc, scale=scale),\n",
    "        genextreme.ppf(0.99, c, loc=loc, scale=scale),\n",
    "        300\n",
    "    )\n",
    "    y = genextreme.pdf(x, c, loc=loc, scale=scale)\n",
    "\n",
    "    # Create label with chunk start and end dates\n",
    "    label = f\"{row['chunk_start_date']} to {row['chunk_end_date']}; KL Divergence = {row['kl_divergence']:.3f}\"\n",
    "\n",
    "    plt.plot(x, y, lw=2, color=colors[i], label=label)\n",
    "\n",
    "plt.xlim(-2, 20)\n",
    "plt.ylim(-0.02, 0.75)\n",
    "plt.title('PDFs of Generalized Extreme Value (GEV) Distributions\\nfor CZR between 2019-05-07 and 2020-04-17')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c178af-2cee-45fd-ac98-577d25f8382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import genextreme\n",
    "\n",
    "def plot_genextreme_distributions(results, colors=None, labels=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    i = 0\n",
    "    for res in results:\n",
    "        c = res['parameters']['c']\n",
    "        loc = res['parameters'].get('loc', 0)\n",
    "        scale = res['parameters'].get('scale', 1)\n",
    "\n",
    "        # Generate x-values safely within distribution support\n",
    "        x = np.linspace(\n",
    "            genextreme.ppf(0.01, c, loc=loc, scale=scale),\n",
    "            genextreme.ppf(0.9, c, loc=loc, scale=scale),\n",
    "            300\n",
    "        )\n",
    "        y = genextreme.pdf(x, c, loc=loc, scale=scale)\n",
    "\n",
    "        color = colors[i] if colors and i < len(colors) else None\n",
    "        label = labels[i] if labels and i < len(labels) else f'{i}: c={c:.2f}'\n",
    "\n",
    "        plt.plot(x, y, lw=2, color=color, label=label)\n",
    "        i += 1\n",
    "\n",
    "    plt.title('Generalized Extreme Value (GEV) Distributions')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4e708-bb5b-4052-ba05-f38408375981",
   "metadata": {},
   "source": [
    "## Anomaly Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92313a-75f4-4e46-90c0-e22ee07aab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anomaly dataframe\n",
    "test_set_name = \"Simulated DistShift+Anom 700\"\n",
    "anom_df = pd.read_sql(eval_template.format(test_set=test_set_name), conn)\n",
    "\n",
    "# if test_set_name == \"Simulated DistShift+Anom 700\":\n",
    "#     # Split into parts\n",
    "#     # 1) Use extract with a regex capturing groups\n",
    "#     pattern = r'^(?P<symbol_raw>[^|]+)\\|std=(?P<min_std>\\d+);(?P<max_std>\\d+)$'\n",
    "#     extracted = anom_df['symbol'].astype(str).str.extract(pattern)\n",
    "    \n",
    "#     # extracted will have NaN for rows that don't match; merge back to original\n",
    "#     anom_df = anom_df.join(extracted)\n",
    "    \n",
    "#     # 2) Clean / convert numeric columns\n",
    "#     anom_df['min_std'] = pd.to_numeric(anom_df['min_std'], errors='coerce')\n",
    "#     anom_df['max_std'] = pd.to_numeric(anom_df['max_std'], errors='coerce')\n",
    "    \n",
    "#     # 3) If you want the cleaned symbol column (no std suffix)\n",
    "#     # Use the captured symbol_raw where present, otherwise keep original string\n",
    "#     anom_df['symbol_clean'] = anom_df['symbol_raw'].where(anom_df['symbol_raw'].notna(), anom_df['symbol'])\n",
    "    \n",
    "#     # Drop helper col if you want\n",
    "#     anom_df = anom_df.drop(columns=['symbol_raw', 'symbol'])\n",
    "#     anom_df = anom_df.rename(columns={'symbol_clean':'symbol'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2308923e-9526-4432-b0b6-ae167a0eb5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8567e48-4c0e-40a2-bebe-318ece7f2e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anom_df[['symbol', 'start_dt']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1afc27-ac80-4ed5-be20-7079d84de8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {}\n",
    "for row in anom_df[[\"model\", \"base_model\"]].drop_duplicates().to_numpy():\n",
    "    key = row[0] + \" + \" + str(row[1])\n",
    "    query_dict[key] = {'dataset': None, 'model': None, 'conformity_score': None, 'conformal_mode': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4d6777-9db1-472e-9288-1472b4c5873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for key in query_dict.keys():\n",
    "    print(str(i) + f\". {key}\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10fd6ac-fa46-4ec2-9763-990762dc8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE EACH OF THESE COMBINATIONS\n",
    "# 1. 'AR(1)-GARCH(1,1) + None'\n",
    "query_dict['AR(1)-GARCH(1,1) + None']['dataset'] = 'argarch_results'\n",
    "query_dict['AR(1)-GARCH(1,1) + None']['model'] = 'AR(1)-GARCH(1,1)'\n",
    "\n",
    "# 1.2. DtACI: Gamma Score + AR(1)-GARCH(1,1)\n",
    "query_dict['DtACI: Gamma Score + AR(1)']['dataset'] = 'dtaci_results_new'\n",
    "query_dict['DtACI: Gamma Score + AR(1)']['model'] = 'AR(1)'\n",
    "query_dict['DtACI: Gamma Score + AR(1)']['conformity_score'] = 'gamma'\n",
    "\n",
    "# 2. DtACI: Residual Normalized Score + AR(1)-GARCH(1,1)\n",
    "query_dict['DtACI: Residual Normalized Score + AR(1)-GARCH(1,1)']['dataset'] = 'dtaci_results_new'\n",
    "query_dict['DtACI: Residual Normalized Score + AR(1)-GARCH(1,1)']['model'] = 'AR(1)-GARCH(1,1)'\n",
    "query_dict['DtACI: Residual Normalized Score + AR(1)-GARCH(1,1)']['conformity_score'] = 'residual_normalized'\n",
    "\n",
    "# 3. DtACI: Residual Normalized Score;I=100 + AR(1)-GARCH(1,1)\n",
    "query_dict['DtACI: Residual Normalized Score;I=100 + AR(1)-GARCH(1,1)']['dataset'] = 'dtaci_results_new'\n",
    "query_dict['DtACI: Residual Normalized Score;I=100 + AR(1)-GARCH(1,1)']['model'] = 'AR(1)-GARCH(1,1);I=100'\n",
    "query_dict['DtACI: Residual Normalized Score;I=100 + AR(1)-GARCH(1,1)']['conformity_score'] = 'residual_normalized'\n",
    "\n",
    "# 4. DtACI: Residual Normalized Score;I=150 + AR(1)-GARCH(1,1)\n",
    "query_dict['DtACI: Residual Normalized Score;I=150 + AR(1)-GARCH(1,1)']['dataset'] = 'dtaci_results_new'\n",
    "query_dict['DtACI: Residual Normalized Score;I=150 + AR(1)-GARCH(1,1)']['model'] = 'AR(1)-GARCH(1,1);I=150'\n",
    "query_dict['DtACI: Residual Normalized Score;I=150 + AR(1)-GARCH(1,1)']['conformity_score'] = 'residual_normalized'\n",
    "\n",
    "# 5. DtACI: Residual Normalized Score;I=50 + AR(1)-GARCH(1,1)\n",
    "query_dict['DtACI: Residual Normalized Score;I=50 + AR(1)-GARCH(1,1)']['dataset'] = 'dtaci_results_new'\n",
    "query_dict['DtACI: Residual Normalized Score;I=50 + AR(1)-GARCH(1,1)']['model'] = 'AR(1)-GARCH(1,1);I=50'\n",
    "query_dict['DtACI: Residual Normalized Score;I=50 + AR(1)-GARCH(1,1)']['conformity_score'] = 'residual_normalized'\n",
    "\n",
    "# 6. NC: Gamma Score + AR(1)\n",
    "query_dict['NC: Gamma Score + AR(1)']['dataset'] = 'conformal_results'\n",
    "query_dict['NC: Gamma Score + AR(1)']['conformal_mode'] = 'naive'\n",
    "query_dict['NC: Gamma Score + AR(1)']['conformity_score'] = 'gamma'\n",
    "\n",
    "# 7. NC: Residual Normalized Score + AR(1)-GARCH(1,1)\n",
    "query_dict['NC: Residual Normalized Score + AR(1)-GARCH(1,1)']['dataset'] = 'conformal_results'\n",
    "query_dict['NC: Residual Normalized Score + AR(1)-GARCH(1,1)']['conformal_mode'] = 'naive'\n",
    "query_dict['NC: Residual Normalized Score + AR(1)-GARCH(1,1)']['conformity_score'] = 'residual_normalized'\n",
    "\n",
    "# 8. OC: Gamma Score + AR(1)\n",
    "query_dict['OC: Gamma Score + AR(1)']['dataset'] = 'conformal_results'\n",
    "query_dict['OC: Gamma Score + AR(1)']['conformal_mode'] = 'online'\n",
    "query_dict['OC: Gamma Score + AR(1)']['conformity_score'] = 'gamma'\n",
    "\n",
    "# 9. OC: Residual Normalized Score + AR(1)-GARCH(1,1)\n",
    "query_dict['OC: Residual Normalized Score + AR(1)-GARCH(1,1)']['dataset'] = 'conformal_results'\n",
    "query_dict['OC: Residual Normalized Score + AR(1)-GARCH(1,1)']['conformal_mode'] = 'online'\n",
    "query_dict['OC: Residual Normalized Score + AR(1)-GARCH(1,1)']['conformity_score'] = 'residual_normalized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc270c-77cc-46d9-9ab3-f69934502841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768493b2-538b-48c9-93c8-c18c7d2a6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_simulator import get_reference_data\n",
    "from model_fitting import ModelFitting\n",
    "\n",
    "def get_anomaly_performance(symbol, start_dt, end_dt, model_name, conformal_mode, conformity_score, \n",
    "                            dataset, model, test_set=\"Real Anomaly\", mkt_utils=mkt_utils):\n",
    "\n",
    "    model_query = \"\"\"\n",
    "        select t.* \n",
    "        from {table} t\n",
    "        where test_set = '{test_set}'\n",
    "        and symbol = '{symbol}'\n",
    "    \"\"\"\n",
    "    formatted_query = model_query.format(table=dataset, test_set = test_set, symbol=symbol)\n",
    "    if conformal_mode is not None:\n",
    "        formatted_query += f\" and conformal_mode = '{conformal_mode}'\"\n",
    "    if conformity_score is not None:\n",
    "        formatted_query += f\" and conformity_score = '{conformity_score}'\"\n",
    "    if model is not None:\n",
    "        formatted_query += f\" and model = '{model}'\"\n",
    "    formatted_query += \" order by t.'index' asc\"\n",
    "\n",
    "    # get data\n",
    "    model_df = pd.read_sql(formatted_query, conn)\n",
    "    # print(formatted_query)\n",
    "\n",
    "    if test_set == \"Real Anomaly\":\n",
    "        ref_data = get_reference_data(symbol=symbol, start_dt = start_dt, end_dt=end_dt, mkt_utils=mkt_utils)[0]\n",
    "        \n",
    "        sub_ref_df = ref_data[-len(model_df):].reset_index(drop=True)\n",
    "        model_df_dt = model_df.merge(sub_ref_df[[\"dlycaldt\"]], left_index=True, right_index=True)\n",
    "    \n",
    "        # add in anomaly flags\n",
    "        model_df_dt[\"anom_flag\"] = 0\n",
    "        \n",
    "        # query real anomaly dataset\n",
    "        real_anomaly_qry = \"\"\"\n",
    "            select *\n",
    "            from manual_anomalies\n",
    "            where symbol = '{symbol}'\n",
    "        \"\"\"\n",
    "        real_anom_record = pd.read_sql(real_anomaly_qry.format(symbol=symbol), conn)\n",
    "        # print(real_anom_record)\n",
    "    \n",
    "        # update anomaly flags\n",
    "        model_df_dt.loc[model_df_dt['dlycaldt'].isin(real_anom_record[\"date\"].unique()), 'anom_flag'] = 1\n",
    "        # print(model_df_dt)\n",
    "        \n",
    "        # Find the index of the row with 1\n",
    "        anom_idx = model_df_dt.index[model_df_dt['anom_flag'] == 1][0]\n",
    "        \n",
    "        # Split into two datasets\n",
    "        before = model_df_dt.loc[:anom_idx-1]      # rows before the 1\n",
    "        after = model_df_dt.loc[anom_idx + 1:]     # rows after the 1\n",
    "    else: # synthetic test set\n",
    "        if test_set == \"Simulated Anomaly 700\":\n",
    "            data_table_name = \"sim_data_anomaly_700\"\n",
    "            # get the anomaly index via querying table\n",
    "            anom_idx = int(pd.read_sql(f\"\"\"select t \n",
    "                   from {data_table_name} a\n",
    "                   where a.id = {symbol}\n",
    "                   and max_flag_anomaly = 1\n",
    "                   \"\"\", conn).iloc[0]['t']) - 400 # only tested on last 300 observations\n",
    "        elif test_set == \"Simulated DistShift+Anom 700\":\n",
    "            data_table_name = \"sim_data_distshift_anom_700\"\n",
    "\n",
    "            # process symbol\n",
    "            sym_id, stds = symbol.split(\"|std=\")\t\n",
    "            min_std, max_std = stds.split(';')\n",
    "\n",
    "            # get the anomaly index via querying table\n",
    "            anom_idx = int(pd.read_sql(f\"\"\"select t \n",
    "                   from {data_table_name} a\n",
    "                   where a.id = {sym_id}\n",
    "                   and a.min_std = {min_std}\n",
    "                   and a.max_std = {max_std}\n",
    "                   and max_flag_anomaly = 1\n",
    "                   \"\"\", conn).iloc[0]['t']) - 400 # only tested on last 300 observations\n",
    "\n",
    "        # print(anom_idx)\n",
    "        # print(model_df.head())\n",
    "        \n",
    "        # Split into two datasets\n",
    "        before = model_df.loc[:anom_idx-1]      # rows before the 1\n",
    "        after = model_df.loc[anom_idx + 1:]     # rows after the 1\n",
    "        # print(before.head())\n",
    "\n",
    "        model_df_dt = model_df.copy()\n",
    "        model_df_dt['anom_flag'] = 0\n",
    "        model_df_dt.loc[anom_idx, 'anom_flag'] = 1\n",
    "\n",
    "    \n",
    "    # create ModelFitting object\n",
    "    m_fitting = ModelFitting(None)\n",
    "\n",
    "    actual_range = max(before['actual'].max(), after['actual'].max()) - min(before['actual'].min(), after['actual'].min())\n",
    "\n",
    "    # before stats\n",
    "    before_stats = m_fitting.get_coverage_stats(before, actual_range = actual_range)\n",
    "    before_stats = {f\"before_{k}\": v for k, v in before_stats.items()}\n",
    "\n",
    "    # after stats\n",
    "    after_stats = m_fitting.get_coverage_stats(after, actual_range = actual_range)\n",
    "    after_stats = {f\"after_{k}\": v for k, v in after_stats.items()}\n",
    "\n",
    "    # combined stats\n",
    "    combined_stats = before_stats | after_stats\n",
    "    \n",
    "    anomaly_detected = (model_df_dt[model_df_dt['anom_flag'] == 1]['within_CI'].astype(bool) == False).all()\n",
    "    band_distance = model_df.loc[anom_idx][\"actual\"] - model_df.loc[anom_idx][\"upper_bound\"]\n",
    "\n",
    "    combined_stats[\"anomaly_detected\"] = bool(anomaly_detected)\n",
    "    combined_stats[\"band_distance\"] = band_distance\n",
    "    combined_stats[\"symbol\"] = symbol\n",
    "    combined_stats[\"start_dt\"] = start_dt\n",
    "    combined_stats[\"end_dt\"] = end_dt\n",
    "    combined_stats[\"model_name\"] = model_name\n",
    "\n",
    "    return combined_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d0b2d4-e214-4ab5-8de7-b4ef4f367f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "anom_results = []\n",
    "for ind, row in tqdm(anom_df.iterrows()):\n",
    "    # if ind == 70:\n",
    "    model_name = row['model'] + \" + \" + str(row['base_model'])\n",
    "    anom_performance_dict = get_anomaly_performance(row['symbol'], start_dt=row['start_dt'], end_dt=row['end_dt'], model_name=model_name, \n",
    "                                                    conformal_mode = query_dict[model_name]['conformal_mode'], \n",
    "                                                    conformity_score = query_dict[model_name]['conformity_score'], \n",
    "                                                    dataset = query_dict[model_name]['dataset'], \n",
    "                                                    model = query_dict[model_name]['model'], test_set=test_set_name)\n",
    "    anom_results.append(anom_performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a8b32-3291-4441-8e44-73254226d81f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(anom_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25640f1c-329f-4d83-a6ee-be68bfbc8cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anom_results_df = pd.DataFrame(anom_results) #.drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c14c0-3338-4e04-81c1-e86726bf51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_results_df['test_set'] = test_set_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40c407-6788-4c20-aea5-1f2756f6ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_results_df #.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789071dc-fcd9-45f3-9bdd-b0b5796d1410",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_results_df.to_sql(\"anomaly_results_analysis\", if_exists='append', index=False, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e836c-06ec-4199-b97e-f84faa39c96a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: get all of the dataset combinations and run to create Sqlite table \n",
    "# get_anomaly_performance(symbol=\"BKCC\", start_dt = \"2014-04-03\", end_dt=\"2015-12-09\", test_set=\"Real Anomaly\", results_dataset=\"argarch_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6501a8-6fe2-48c0-a929-9fb0535678a5",
   "metadata": {},
   "source": [
    "### Anomaly Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207713be-a808-4173-92a4-930be0a791d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_name = 'Simulated DistShift+Anom 700'\n",
    "anom_results_df = pd.read_sql(f\"\"\"\n",
    "    select * from anomaly_results_analysis \n",
    "    where test_set = '{test_set_name}' \n",
    "    \"\"\", con = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03719146-fad0-4d02-98d2-46fd79868d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_order, _ = get_ordered_models(anom_results_df, \"model_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7232c8-d8ed-4f5c-9b81-9a1232902e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_set_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1feaa2b-d7ed-4b8e-86be-9cd3d17c53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Select only relevant columns\n",
    "cols = [\n",
    "    'model_name',\n",
    "    'before_coverage', 'after_coverage',\n",
    "    'before_avg_width', 'after_avg_width',\n",
    "    'before_median_width', 'after_median_width',\n",
    "    'before_max_width', 'after_max_width',\n",
    "    'before_mwi_score', 'after_mwi_score',\n",
    "    'before_cwc_score', 'after_cwc_score',\n",
    "    'after_min_width'\n",
    "]\n",
    "\n",
    "df = anom_results_df[cols].copy()\n",
    "\n",
    "# Identify before/after column pairs\n",
    "pairs = [\n",
    "    ('coverage', 'before_coverage', 'after_coverage'),\n",
    "    ('avg_width', 'before_avg_width', 'after_avg_width'),\n",
    "    ('median_width', 'before_median_width', 'after_median_width'),\n",
    "    ('max_width', 'before_max_width', 'after_max_width'),\n",
    "    ('mwi_score', 'before_mwi_score', 'after_mwi_score'),\n",
    "    ('cwc_score', 'before_cwc_score', 'after_cwc_score'),\n",
    "]\n",
    "\n",
    "# Compute percent differences for each pair\n",
    "for name, before_col, after_col in pairs:\n",
    "    df[f'{name}_pct_diff'] = 100 * (df[after_col] - df[before_col]) / df[before_col]\n",
    "\n",
    "# Now group by model_name and compute the mean of only the percent-diff columns\n",
    "pct_diff_cols = [f'{name}_pct_diff' for name, _, _ in pairs]\n",
    "grouped = df.groupby('model_name', as_index=False)[pct_diff_cols].mean()\n",
    "\n",
    "grouped #. to_csv(\"real_anomaly_before_after_pctdiff.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6960035a-4966-4652-b4dc-57aa872912b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Reindex dataframe to follow custom order\n",
    "df = grouped.copy()\n",
    "df[\"model_name\"] = pd.Categorical(df[\"model_name\"], categories=custom_order, ordered=True)\n",
    "df = df.sort_values(\"model_name\")\n",
    "\n",
    "\n",
    "# === Plot ===\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=3, shared_yaxes=True,\n",
    "    subplot_titles=(\"Coverage Δ\", \"Avg Width Δ\", \"CWC Δ\")\n",
    ")\n",
    "\n",
    "colors_cov = ['green' if x > 0 else 'red' for x in df[\"coverage_pct_diff\"]]\n",
    "colors_wid = ['green' if x > 0 else 'red' for x in df[\"avg_width_pct_diff\"]]\n",
    "colors_mwi = ['green' if x > 0 else 'red' for x in df[\"cwc_score_pct_diff\"]]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        y=df[\"model_name\"],\n",
    "        x=df[\"coverage_pct_diff\"],\n",
    "        orientation='h',\n",
    "        marker_color=colors_cov,\n",
    "        name=\"Coverage Δ\"\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        y=df[\"model_name\"],\n",
    "        x=df[\"avg_width_pct_diff\"],\n",
    "        orientation='h',\n",
    "        marker_color=colors_wid,\n",
    "        name=\"Width Δ\"\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        y=df[\"model_name\"],\n",
    "        x=df[\"cwc_score_pct_diff\"],\n",
    "        orientation='h',\n",
    "        marker_color=colors_mwi,\n",
    "        name=\"CWC Δ\"\n",
    "    ),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=1100,\n",
    "    showlegend=False,\n",
    "    template=\"plotly_white\",\n",
    "    title_text=f\"Before vs After Changes by Model ({test_set_name})\"\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Δ Coverage (%)\", zeroline=True, zerolinecolor=\"black\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Δ Avg Width (%)\", zeroline=True, zerolinecolor=\"black\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Δ CWC (%)\", zeroline=True, zerolinecolor=\"black\", row=1, col=3)\n",
    "fig.update_yaxes(title_text=\"\", categoryorder=\"array\", categoryarray=custom_order)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504b2bb-05f3-4fa3-8fad-1734b93b082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_results_df[\"model_name\"] = pd.Categorical(anom_results_df[\"model_name\"], categories=custom_order, ordered=True)\n",
    "anom_results_df = anom_results_df.sort_values(\"model_name\")\n",
    "anom_results_df[[\n",
    "    'model_name',\n",
    "    'anomaly_detected', 'band_distance'  # only after exists\n",
    "]].groupby('model_name').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7654898e-ded0-488c-a316-5b7b6fc59752",
   "metadata": {},
   "source": [
    "### Anomaly + Distribution Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ec54ac-3fdc-4c11-9137-217dd3490173",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_name = 'Simulated DistShift+Anom 700'\n",
    "anom_results_df = pd.read_sql(f\"\"\"\n",
    "    select * \n",
    "    from anomaly_results_analysis \n",
    "    where test_set = '{test_set_name}' \n",
    "    and model_name not like '%Gamma%'\n",
    "    \"\"\", con = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94211dda-9d97-4cdf-9eda-f76aeadf630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_results_df.sort_values('band_distance')[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe00570a-ce33-4b50-ad41-928985beacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = anom_results_df.reset_index()\n",
    "df = df[df['start_std'] == 7].sort_values('band_distance')\n",
    "\n",
    "# map model names to numeric codes for coloring\n",
    "df['model_code'] = df['model_name'].astype('category').cat.codes\n",
    "\n",
    "df.plot.scatter(\n",
    "    x='index',\n",
    "    y='band_distance',\n",
    "    c='model_code',\n",
    "    cmap='viridis',       # or any other colormap\n",
    "    figsize=(8,4),\n",
    ")\n",
    "\n",
    "plt.title(\"Band Distance (start_std = 7)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Band Distance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb709a7-a75c-4ffd-87fd-cc44e8d0085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_results_df[['start_std', 'end_std']] = (\n",
    "    anom_results_df['symbol']\n",
    "      .str.extract(r'std=(\\d+);(\\d+)')\n",
    "      .astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67593be4-e05a-4402-b2f0-8a724b2a9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_width_df = anom_results_df[[\n",
    "    'model_name', 'start_std', 'end_std',\n",
    "    'after_avg_width'  # only after exists\n",
    "]].groupby(['model_name', 'start_std', 'end_std']).mean().reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ef887-2aae-4c3a-a1f8-f109991fc11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_width_df['model_name'] =  [val.split(\" + \")[0].replace(\": Residual Normalized Score\", \"\") for val in avg_width_df['model_name'].to_list()]\n",
    "avg_width_df.pivot(index=\"model_name\", columns=\"start_std\", values=\"after_avg_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f97bb-97fc-4ff9-8bd0-cffbc509e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_results_df[\"model_name\"] = pd.Categorical(anom_results_df[\"model_name\"], categories=custom_order, ordered=True)\n",
    "test_df = anom_results_df[[\n",
    "    'model_name', 'start_std', 'end_std',\n",
    "    'anomaly_detected', 'band_distance'  # only after exists\n",
    "]].groupby(['model_name', 'start_std', 'end_std']).mean().reset_index().dropna()\n",
    "test_df['model_name'] =  [val.split(\" + \")[0].replace(\": Residual Normalized Score\", \"\") for val in test_df['model_name'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9457891-ae5d-44b9-a0a3-27855cf64eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pivot1 = test_df.pivot(index=\"model_name\", columns=\"start_std\", values=\"anomaly_detected\")\n",
    "pivot2 = test_df.pivot(index=\"model_name\", columns=\"start_std\", values=\"band_distance\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8), sharey=True)\n",
    "\n",
    "sns.heatmap(pivot1, annot=True, fmt=\".2f\", ax=axes[0])\n",
    "axes[0].set_title(\"Anomaly Detection Rate\", fontsize=14)\n",
    "axes[0].set_xlabel(\"Start STD\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Model Name\", fontsize=12)\n",
    "\n",
    "sns.heatmap(pivot2, annot=True, fmt=\".2f\", ax=axes[1], cmap=\"viridis\")\n",
    "axes[1].set_title(\"Avg. Band Distance\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Start STD\", fontsize=12)\n",
    "axes[1].set_ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a577d2ab-ff30-4679-973c-1ef374d64204",
   "metadata": {},
   "source": [
    "### Combined Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3140a86-a762-4906-93a2-5f2ae4040f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_chart_df = pd.read_sql(\"\"\"\n",
    "select test_set, model_name, \n",
    "       avg((after_coverage - before_coverage)/before_coverage) * 100 as coverage_pct_diff, \n",
    "       avg((after_avg_width - before_avg_width)/before_avg_width) * 100 as avg_width_pct_diff\n",
    "from anomaly_results_analysis\n",
    "group by test_set, model_name\n",
    "\"\"\", conn)\n",
    "\n",
    "anom_chart_df = pd.read_sql(\"\"\"\n",
    "select test_set, model_name, \n",
    "       avg(before_coverage) as mean_before_coverage,\n",
    "       avg(after_coverage) as mean_after_coverage,\n",
    "       avg(before_avg_width) as mean_before_avg_width,\n",
    "       avg(after_avg_width) as mean_after_avg_width,\n",
    "       avg(before_mwi_score) as mean_before_mwi_score,\n",
    "       avg(after_mwi_score) as mean_after_mwi_score,\n",
    "       avg(before_cwc_score) as mean_before_cwc_score,\n",
    "       avg(after_cwc_score) as mean_after_cwc_score\n",
    "from anomaly_results_analysis\n",
    "where model_name not like '%Gamma%'\n",
    "group by test_set, model_name\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fa6e8-8451-4c6f-9759-57870a7f6c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anom_chart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b95b4f-547f-4581-9fbb-a21021a3ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_names, _ = get_ordered_models(anom_chart_df, 'model_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e4496-8e16-4c58-b8c4-c35b044363eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "categories_inner = ordered_names\n",
    "categories_outer = anom_chart_df['test_set'].unique().tolist()[::-1]\n",
    "\n",
    "# === Plot ===\n",
    "values1 = []\n",
    "values2 = []\n",
    "y_outer = []\n",
    "y_inner = []\n",
    "colors1 = []\n",
    "colors2 = []\n",
    "\n",
    "for outer in categories_outer:\n",
    "    for inner in categories_inner:\n",
    "        value_row = anom_chart_df[\n",
    "            (anom_chart_df['test_set'] == outer) &\n",
    "            (anom_chart_df['model_name'] == inner)\n",
    "        ]\n",
    "        values1.append(value_row['coverage_pct_diff'].iloc[0])\n",
    "        values2.append(value_row['avg_width_pct_diff'].iloc[0])\n",
    "        colors1.append('green' if values1[-1] > 0 else  'red')\n",
    "        colors2.append('green' if values2[-1] > 0 else  'red')\n",
    "        y_outer.append(outer)\n",
    "        y_inner.append(inner.split(\" + \")[0])  # display clean model name\n",
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2, shared_yaxes=True,\n",
    "    subplot_titles=(\"Coverage Δ\", \"Mean Width Δ\")\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values1,\n",
    "    y=[y_outer, y_inner],  # multi-category y-axis\n",
    "    orientation='h',       # horizontal bars\n",
    "    name='Metric 1',\n",
    "    marker_color=colors1,\n",
    "    text=[f\"{v:.1f}\" if v > 0 else \"\" for v in values1],     # display rounded values\n",
    "    textposition='auto',                    # inside or next to bars\n",
    "    texttemplate='%{text}'                  # use the preformatted string\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values2,\n",
    "    y=[y_outer, y_inner],  # multi-category y-axis\n",
    "    orientation='h',       # horizontal bars\n",
    "    name='Metric 2',\n",
    "    marker_color=colors2,\n",
    "    text=[f\"{v:.1f}\" if v > 0 else \"\" for v in values2],     # display rounded values\n",
    "    textposition='auto',                    # inside or next to bars\n",
    "    texttemplate='%{text}'                  # use the preformatted string\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Multi-Category Horizontal Bar Chart',\n",
    "    yaxis_title='Test Set / Model',\n",
    "    barmode='group'\n",
    "    \n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title='Avg. Coverage % Diff',\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis2=dict(\n",
    "        title='Avg. Mean Width % Diff',\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    width=1100,\n",
    "    showlegend=False,\n",
    "    template=\"plotly_white\",\n",
    "    title_text=f\"Before vs After Changes by Anomaly Test Set & Model\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    yaxis=dict(showgrid=True)\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f3b08-ec88-4f54-9510-2887c5f023a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "categories_inner = ordered_names\n",
    "categories_outer = anom_chart_df['test_set'].unique().tolist()[::-1]\n",
    "categories_outer = [c for c in categories_outer if c != 'Simulated DistShift+Anom 700']\n",
    "\n",
    "values_cov_before = []\n",
    "values_cov_after = []\n",
    "values_width_before = []\n",
    "values_width_after = []\n",
    "values_mwi_before, values_mwi_after = [], []\n",
    "values_cwc_before, values_cwc_after = [], []\n",
    "y_outer = []\n",
    "y_inner = []\n",
    "\n",
    "for outer in categories_outer:\n",
    "    for inner in categories_inner:\n",
    "        value_row = anom_chart_df[\n",
    "            (anom_chart_df['test_set'] == outer) &\n",
    "            (anom_chart_df['model_name'] == inner)\n",
    "        ]\n",
    "        if value_row.empty:\n",
    "            continue\n",
    "\n",
    "        values_cov_before.append(value_row['mean_before_coverage'].iloc[0])\n",
    "        values_cov_after.append(value_row['mean_after_coverage'].iloc[0])\n",
    "        \n",
    "        values_width_before.append(value_row['mean_before_avg_width'].iloc[0])\n",
    "        values_width_after.append(value_row['mean_after_avg_width'].iloc[0])\n",
    "        \n",
    "        values_mwi_before.append(value_row['mean_before_mwi_score'].iloc[0])\n",
    "        values_mwi_after.append(value_row['mean_after_mwi_score'].iloc[0])\n",
    "        \n",
    "        values_cwc_before.append(value_row['mean_before_cwc_score'].iloc[0])\n",
    "        values_cwc_after.append(value_row['mean_after_cwc_score'].iloc[0])\n",
    "        \n",
    "\n",
    "        y_outer.append(outer.replace(\" 700\", \"\"))\n",
    "        y_inner.append(inner.split(\" + \")[0].replace(\": Residual Normalized Score\", \"\"))\n",
    "\n",
    "# === Plot ===\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=3, shared_yaxes=True,\n",
    "    subplot_titles=(\"Δ Avg. Coverage\", \"Δ Avg. Mean Width\", \"Δ Avg. MWI Score\")\n",
    ")\n",
    "\n",
    "# Coverage bars\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_cov_before,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. Coverage (Before)',\n",
    "    marker_color='rgba(31, 119, 180, 0.6)',\n",
    "    text=[f\"{v:.2f}\" for v in values_cov_before],\n",
    "    textposition='auto'\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_cov_after,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. Coverage (After)',\n",
    "    marker_color='rgba(31, 119, 180, 1.0)',\n",
    "    text=[f\"{v:.2f}\" for v in values_cov_after],\n",
    "    textposition='auto'\n",
    "), row=1, col=1)\n",
    "\n",
    "# Avg Width bars\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_width_before,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. Mean Width (Before)',\n",
    "    marker_color='rgba(44, 160, 44, 0.6)',\n",
    "    text=[f\"{v:.2f}\" for v in values_width_before],\n",
    "    textposition='auto'\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_width_after,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. Mean Width (After)',\n",
    "    marker_color='rgba(44, 160, 44, 1.0)',\n",
    "    text=[f\"{v:.2f}\" for v in values_width_after],\n",
    "    textposition='auto'\n",
    "), row=1, col=2)\n",
    "\n",
    "# Avg MWI score bars\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_mwi_before,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. MWI Score (Before)',\n",
    "    marker_color='rgba(214, 39, 40, 0.6) ',\n",
    "    text=[f\"{v:.2f}\" for v in values_mwi_before],\n",
    "    textposition='auto'\n",
    "), row=1, col=3)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_mwi_after,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. MWI Score (After)',\n",
    "    marker_color='rgba(214, 39, 40, 1.0) ',\n",
    "    text=[f\"{v:.2f}\" for v in values_mwi_after],\n",
    "    textposition='auto'\n",
    "), row=1, col=3)\n",
    "\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    height=820,\n",
    "    width=1100,\n",
    "    barmode='group',\n",
    "    showlegend=True,\n",
    "    template='plotly_white',\n",
    "    title_text=f\"Before vs After Comparison by Test Set & Model (Anomaly)\"\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='avg(Coverage)', row=1, col=1, tickformat=\".1f\", range=[90,100])\n",
    "fig.update_xaxes(title_text='avg(Mean Width)', row=1, col=2, tickformat=\".1f\", range=[0,0.75])\n",
    "fig.update_xaxes(title_text='avg(MWI Score)', row=1, col=3, tickformat=\".1f\")\n",
    "fig.update_yaxes(showgrid=True)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c0fc14-6bab-441b-b5ce-0bb1098f06a1",
   "metadata": {},
   "source": [
    "## Distribution Shift Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c03d87-20e7-4df4-b767-a055ad56655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_name = 'Simulated Distribution Shift 700'\n",
    "distshift_df = pd.read_sql(eval_template.format(test_set=test_set_name), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7faa0-fe39-4594-8ecf-5ed7b10cbe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {}\n",
    "for row in distshift_df[[\"model\", \"base_model\"]].drop_duplicates().to_numpy():\n",
    "    key = row[0] + \" + \" + str(row[1])\n",
    "    query_dict[key] = {'dataset': None, 'model': None, 'conformity_score': None, 'conformal_mode': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfab9ac-0d35-42ba-9a74-ad55d36eee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE EACH OF THESE COMBINATIONS\n",
    "# 1. 'AR(1)-GARCH(1,1) + None'\n",
    "query_dict['AR(1)-GARCH(1,1) + None']['dataset'] = 'argarch_results'\n",
    "query_dict['AR(1)-GARCH(1,1) + None']['model'] = 'AR(1)-GARCH(1,1)'\n",
    "\n",
    "# 1.2. DtACI: Gamma Score + AR(1)-GARCH(1,1)\n",
    "query_dict['DtACI: Gamma Score + AR(1)']['dataset'] = 'dtaci_results_new'\n",
    "query_dict['DtACI: Gamma Score + AR(1)']['model'] = 'AR(1)'\n",
    "query_dict['DtACI: Gamma Score + AR(1)']['conformity_score'] = 'gamma'\n",
    "\n",
    "# 2. DtACI: Residual Normalized Score + AR(1)-GARCH(1,1)\n",
    "query_dict['DtACI: Residual Normalized Score + AR(1)-GARCH(1,1)']['dataset'] = 'dtaci_results_new'\n",
    "query_dict['DtACI: Residual Normalized Score + AR(1)-GARCH(1,1)']['model'] = 'AR(1)-GARCH(1,1)'\n",
    "query_dict['DtACI: Residual Normalized Score + AR(1)-GARCH(1,1)']['conformity_score'] = 'residual_normalized'\n",
    "\n",
    "# 3. DtACI: Residual Normalized Score;I=100 + AR(1)-GARCH(1,1)\n",
    "query_dict['DtACI: Residual Normalized Score;I=100 + AR(1)-GARCH(1,1)']['dataset'] = 'dtaci_results_new'\n",
    "query_dict['DtACI: Residual Normalized Score;I=100 + AR(1)-GARCH(1,1)']['model'] = 'AR(1)-GARCH(1,1);I=100'\n",
    "query_dict['DtACI: Residual Normalized Score;I=100 + AR(1)-GARCH(1,1)']['conformity_score'] = 'residual_normalized'\n",
    "\n",
    "# 4. DtACI: Residual Normalized Score;I=150 + AR(1)-GARCH(1,1)\n",
    "query_dict['DtACI: Residual Normalized Score;I=150 + AR(1)-GARCH(1,1)']['dataset'] = 'dtaci_results_new'\n",
    "query_dict['DtACI: Residual Normalized Score;I=150 + AR(1)-GARCH(1,1)']['model'] = 'AR(1)-GARCH(1,1);I=150'\n",
    "query_dict['DtACI: Residual Normalized Score;I=150 + AR(1)-GARCH(1,1)']['conformity_score'] = 'residual_normalized'\n",
    "\n",
    "# 5. DtACI: Residual Normalized Score;I=50 + AR(1)-GARCH(1,1)\n",
    "query_dict['DtACI: Residual Normalized Score;I=50 + AR(1)-GARCH(1,1)']['dataset'] = 'dtaci_results_new'\n",
    "query_dict['DtACI: Residual Normalized Score;I=50 + AR(1)-GARCH(1,1)']['model'] = 'AR(1)-GARCH(1,1);I=50'\n",
    "query_dict['DtACI: Residual Normalized Score;I=50 + AR(1)-GARCH(1,1)']['conformity_score'] = 'residual_normalized'\n",
    "\n",
    "# 6. NC: Gamma Score + AR(1)\n",
    "query_dict['NC: Gamma Score + AR(1)']['dataset'] = 'conformal_results'\n",
    "query_dict['NC: Gamma Score + AR(1)']['conformal_mode'] = 'naive'\n",
    "query_dict['NC: Gamma Score + AR(1)']['conformity_score'] = 'gamma'\n",
    "\n",
    "# 7. NC: Residual Normalized Score + AR(1)-GARCH(1,1)\n",
    "query_dict['NC: Residual Normalized Score + AR(1)-GARCH(1,1)']['dataset'] = 'conformal_results'\n",
    "query_dict['NC: Residual Normalized Score + AR(1)-GARCH(1,1)']['conformal_mode'] = 'naive'\n",
    "query_dict['NC: Residual Normalized Score + AR(1)-GARCH(1,1)']['conformity_score'] = 'residual_normalized'\n",
    "\n",
    "# 8. OC: Gamma Score + AR(1)\n",
    "query_dict['OC: Gamma Score + AR(1)']['dataset'] = 'conformal_results'\n",
    "query_dict['OC: Gamma Score + AR(1)']['conformal_mode'] = 'online'\n",
    "query_dict['OC: Gamma Score + AR(1)']['conformity_score'] = 'gamma'\n",
    "\n",
    "# 9. OC: Residual Normalized Score + AR(1)-GARCH(1,1)\n",
    "query_dict['OC: Residual Normalized Score + AR(1)-GARCH(1,1)']['dataset'] = 'conformal_results'\n",
    "query_dict['OC: Residual Normalized Score + AR(1)-GARCH(1,1)']['conformal_mode'] = 'online'\n",
    "query_dict['OC: Residual Normalized Score + AR(1)-GARCH(1,1)']['conformity_score'] = 'residual_normalized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639d180-551c-47c9-84da-5d1a2cb1b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_simulator import get_reference_data\n",
    "from model_fitting import ModelFitting\n",
    "\n",
    "def get_distshift_performance(symbol, start_dt, end_dt, model_name, conformal_mode, conformity_score, \n",
    "                            dataset, model, test_set, distshift_idx = 200, distshift_dt = '2020-02-03', mkt_utils=mkt_utils):\n",
    "\n",
    "    model_query = \"\"\"\n",
    "        select t.* \n",
    "        from {table} t\n",
    "        where test_set = '{test_set}'\n",
    "        and symbol = '{symbol}'\n",
    "    \"\"\"\n",
    "    formatted_query = model_query.format(table=dataset, test_set = test_set, symbol=symbol)\n",
    "    if conformal_mode is not None:\n",
    "        formatted_query += f\" and conformal_mode = '{conformal_mode}'\"\n",
    "    if conformity_score is not None:\n",
    "        formatted_query += f\" and conformity_score = '{conformity_score}'\"\n",
    "    if model is not None:\n",
    "        formatted_query += f\" and model = '{model}'\"\n",
    "    formatted_query += \" order by t.'index' asc\"\n",
    "\n",
    "    # get data\n",
    "    model_df = pd.read_sql(formatted_query, conn)\n",
    "    # print(formatted_query)\n",
    "\n",
    "    if test_set == \"Real Distribution Shift\":\n",
    "        ref_data = get_reference_data(symbol=symbol, start_dt = start_dt, end_dt=end_dt, mkt_utils=mkt_utils)[0]\n",
    "        \n",
    "        sub_ref_df = ref_data[-len(model_df):].reset_index(drop=True)\n",
    "        model_df_dt = model_df.merge(sub_ref_df[[\"dlycaldt\"]], left_index=True, right_index=True)\n",
    "        \n",
    "        # Find the index of the row with 1\n",
    "        distshift_idx = model_df_dt.index[model_df_dt['dlycaldt'].astype(str) == distshift_dt][0]\n",
    "        \n",
    "        # Split into two datasets\n",
    "        before = model_df_dt.loc[:distshift_idx-1]      # rows before the 1\n",
    "        after = model_df_dt.loc[distshift_idx:]     # rows after the 1\n",
    "    else: # synthetic test set\n",
    "        # Split into two datasets\n",
    "        before = model_df.loc[:distshift_idx-1]      # rows before the 1\n",
    "        after = model_df.loc[distshift_idx:]     # rows after the 1\n",
    "\n",
    "        model_df_dt = model_df.copy()\n",
    "\n",
    "    \n",
    "    # create ModelFitting object\n",
    "    m_fitting = ModelFitting(None)\n",
    "\n",
    "    actual_range = max(before['actual'].max(), after['actual'].max()) - min(before['actual'].min(), after['actual'].min())\n",
    "\n",
    "    # before stats\n",
    "    before_stats = m_fitting.get_coverage_stats(before, actual_range = actual_range)\n",
    "    before_stats = {f\"before_{k}\": v for k, v in before_stats.items()}\n",
    "\n",
    "    # after stats\n",
    "    after_stats = m_fitting.get_coverage_stats(after, actual_range = actual_range)\n",
    "    after_stats = {f\"after_{k}\": v for k, v in after_stats.items()}\n",
    "\n",
    "    # combined stats\n",
    "    combined_stats = before_stats | after_stats\n",
    "    \n",
    "    combined_stats[\"symbol\"] = symbol\n",
    "    combined_stats[\"start_dt\"] = start_dt\n",
    "    combined_stats[\"end_dt\"] = end_dt\n",
    "    combined_stats[\"model_name\"] = model_name\n",
    "\n",
    "    return combined_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6306950b-0c61-4b51-a75a-6f59823d7dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "distshift_results = []\n",
    "for ind, row in tqdm(distshift_df.iterrows()):\n",
    "    # if ind == 70:\n",
    "    model_name = row['model'] + \" + \" + str(row['base_model'])\n",
    "    distshift_performance_dict = get_distshift_performance(row['symbol'], start_dt=row['start_dt'], end_dt=row['end_dt'], model_name=model_name, \n",
    "                                                    conformal_mode = query_dict[model_name]['conformal_mode'], \n",
    "                                                    conformity_score = query_dict[model_name]['conformity_score'], \n",
    "                                                    dataset = query_dict[model_name]['dataset'], \n",
    "                                                    model = query_dict[model_name]['model'], test_set=test_set_name)\n",
    "    distshift_results.append(distshift_performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba5d7e-7dfe-460b-9c14-3310183d4c02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distshift_results_df = pd.DataFrame(distshift_results) #.drop(columns = ['index'])\n",
    "distshift_results_df['test_set'] = test_set_name \n",
    "distshift_results_df[[\"test_set\", \"symbol\", \"model_name\", \"before_coverage\", \"after_coverage\", \"before_mwi_score\", \"after_mwi_score\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd70c197-6dd6-4a54-97d3-232b31497662",
   "metadata": {},
   "outputs": [],
   "source": [
    "distshift_results_df.to_sql(\"distshift_results_analysis\", if_exists='append', index=False, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f383619d-bb18-4f58-9031-92b43d67abba",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91970995-b5c8-470d-8432-0363f72fc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_inextreme = get_data('Real Distribution Shift (in Extreme)')\n",
    "symbols_list = tuple(dist_inextreme['symbol'].unique())\n",
    "\n",
    "anom_chart_df = pd.read_sql(f\"\"\"\n",
    "SELECT test_set, \n",
    "       model_name,\n",
    "       AVG(before_coverage) AS mean_before_coverage,\n",
    "       AVG(after_coverage) AS mean_after_coverage,\n",
    "       AVG(before_avg_width) AS mean_before_avg_width,\n",
    "       AVG(after_avg_width) AS mean_after_avg_width,\n",
    "       AVG(before_mwi_score) AS mean_before_mwi_score,\n",
    "       AVG(after_mwi_score) AS mean_after_mwi_score\n",
    "FROM distshift_results_analysis\n",
    "WHERE model_name NOT LIKE '%Gamma%'\n",
    "  AND symbol IN {symbols_list}\n",
    "GROUP BY test_set, model_name\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3a7c5-6bce-4c3a-8102-73b542718cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_names, _ = get_ordered_models(anom_chart_df, 'model_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9776d876-6a82-4564-a067-2573b722b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_chart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0f5ed-47e0-496a-9d78-49be54f2945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "categories_inner = ordered_names\n",
    "categories_outer = anom_chart_df['test_set'].unique().tolist()[::-1]\n",
    "categories_outer = [c for c in categories_outer if c != 'Simulated DistShift+Anom 700']\n",
    "\n",
    "values_cov_before = []\n",
    "values_cov_after = []\n",
    "values_width_before = []\n",
    "values_width_after = []\n",
    "values_mwi_before, values_mwi_after = [], []\n",
    "y_outer = []\n",
    "y_inner = []\n",
    "\n",
    "for outer in categories_outer:\n",
    "    for inner in categories_inner:\n",
    "        value_row = anom_chart_df[\n",
    "            (anom_chart_df['test_set'] == outer) &\n",
    "            (anom_chart_df['model_name'] == inner)\n",
    "        ]\n",
    "        if value_row.empty:\n",
    "            continue\n",
    "\n",
    "        values_cov_before.append(value_row['mean_before_coverage'].iloc[0])\n",
    "        values_cov_after.append(value_row['mean_after_coverage'].iloc[0])\n",
    "        \n",
    "        values_width_before.append(value_row['mean_before_avg_width'].iloc[0])\n",
    "        values_width_after.append(value_row['mean_after_avg_width'].iloc[0])\n",
    "        \n",
    "        values_mwi_before.append(value_row['mean_before_mwi_score'].iloc[0])\n",
    "        values_mwi_after.append(value_row['mean_after_mwi_score'].iloc[0])\n",
    "        \n",
    "\n",
    "        y_outer.append(outer)\n",
    "        y_inner.append(inner.split(\" + \")[0].replace(\": Residual Normalized Score\", \"\"))\n",
    "\n",
    "# === Plot ===\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=3, shared_yaxes=True,\n",
    "    subplot_titles=(\"Δ Avg. Coverage\", \"Δ Avg. Mean Width\", \"Δ Avg. MWI Score\")\n",
    ")\n",
    "\n",
    "# Coverage bars\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_cov_before,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. Coverage (Before)',\n",
    "    marker_color='rgba(31, 119, 180, 0.6)',\n",
    "    text=[f\"{v:.2f}\" for v in values_cov_before],\n",
    "    textposition='auto'\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_cov_after,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. Coverage (After)',\n",
    "    marker_color='rgba(31, 119, 180, 1.0)',\n",
    "    text=[f\"{v:.2f}\" for v in values_cov_after],\n",
    "    textposition='auto'\n",
    "), row=1, col=1)\n",
    "\n",
    "# Avg Width bars\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_width_before,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. Mean Width (Before)',\n",
    "    marker_color='rgba(44, 160, 44, 0.6)',\n",
    "    text=[f\"{v:.2f}\" for v in values_width_before],\n",
    "    textposition='auto'\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_width_after,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. Mean Width (After)',\n",
    "    marker_color='rgba(44, 160, 44, 1.0)',\n",
    "    text=[f\"{v:.2f}\" for v in values_width_after],\n",
    "    textposition='auto'\n",
    "), row=1, col=2)\n",
    "\n",
    "# Avg MWI score bars\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_mwi_before,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. MWI Score (Before)',\n",
    "    marker_color='rgba(214, 39, 40, 0.6) ',\n",
    "    text=[f\"{v:.2f}\" for v in values_mwi_before],\n",
    "    textposition='auto'\n",
    "), row=1, col=3)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_mwi_after,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. MWI Score (After)',\n",
    "    marker_color='rgba(214, 39, 40, 1.0) ',\n",
    "    text=[f\"{v:.2f}\" for v in values_mwi_after],\n",
    "    textposition='auto'\n",
    "), row=1, col=3)\n",
    "\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    #height=820,\n",
    "    height = 600,\n",
    "    width=1100,\n",
    "    barmode='group',\n",
    "    showlegend=True,\n",
    "    template='plotly_white',\n",
    "    title_text=f\"Before vs After Comparison by Test Set & Model (Distribution Shift in Extreme)\"\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='avg(Coverage)', row=1, col=1, tickformat=\".1f\", range=[85,100])\n",
    "fig.update_xaxes(title_text='avg(Mean Width)', row=1, col=2, tickformat=\".1f\", range=[0,1.4])\n",
    "fig.update_xaxes(title_text='avg(MWI Score)', row=1, col=3, tickformat=\".1f\")\n",
    "fig.update_yaxes(showgrid=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a77c97f-184c-4309-8a74-8ac352b64715",
   "metadata": {},
   "source": [
    "#### Simulated Anomaly + Distribution Shift Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c088ff-2a13-40a6-88d2-fa6efd049aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_anomdistshift_chart_df = pd.read_sql(\"\"\"\n",
    "select test_set, \n",
    "       model_name,\n",
    "       substr(symbol, instr(symbol, 'std=') + 4) as std_category, \n",
    "       avg(before_coverage) as mean_before_coverage,\n",
    "       avg(after_coverage) as mean_after_coverage,\n",
    "       avg(before_avg_width) as mean_before_avg_width,\n",
    "       avg(after_avg_width) as mean_after_avg_width,\n",
    "       avg(before_mwi_score) as mean_before_mwi_score,\n",
    "       avg(after_mwi_score) as mean_after_mwi_score\n",
    "from distshift_results_analysis\n",
    "where model_name not like '%Gamma%'\n",
    "and test_set = 'Simulated DistShift+Anom 700'\n",
    "group by 1, 2, 3\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23d5ac-b5ab-4fba-b988-ae85878fa9fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim_anomdistshift_chart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afa692-3b3e-402c-abc8-327835b34480",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_names, _ = get_ordered_models(sim_anomdistshift_chart_df, 'model_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82cf93f-eb92-4e07-9324-a750461eda2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "sim_anom_chart_df = sim_anomdistshift_chart_df\n",
    "categories_inner = ordered_names\n",
    "categories_outer = list(sim_anom_chart_df['std_category'].unique()) #sim_anom_chart_df['test_set'].unique().tolist()[::-1]\n",
    "\n",
    "values_cov_before = []\n",
    "values_cov_after = []\n",
    "values_width_before = []\n",
    "values_width_after = []\n",
    "values_mwi_before, values_mwi_after = [], []\n",
    "y_outer = []\n",
    "y_inner = []\n",
    "\n",
    "for outer in categories_outer:\n",
    "    for inner in categories_inner:\n",
    "        value_row = sim_anom_chart_df[\n",
    "            (sim_anom_chart_df['std_category'] == outer) &\n",
    "            (sim_anom_chart_df['model_name'] == inner)\n",
    "        ]\n",
    "        if value_row.empty:\n",
    "            continue\n",
    "\n",
    "        values_cov_before.append(value_row['mean_before_coverage'].iloc[0])\n",
    "        values_cov_after.append(value_row['mean_after_coverage'].iloc[0])\n",
    "        \n",
    "        values_width_before.append(value_row['mean_before_avg_width'].iloc[0])\n",
    "        values_width_after.append(value_row['mean_after_avg_width'].iloc[0])\n",
    "        \n",
    "        values_mwi_before.append(value_row['mean_before_mwi_score'].iloc[0])\n",
    "        values_mwi_after.append(value_row['mean_after_mwi_score'].iloc[0])\n",
    "        \n",
    "\n",
    "        y_outer.append(outer)\n",
    "        y_inner.append(inner.split(\" + \")[0].replace(\": Residual Normalized Score\", \"\"))\n",
    "\n",
    "# === Plot ===\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=3, shared_yaxes=True,\n",
    "    subplot_titles=(\"Δ Avg. Coverage\", \"Δ Avg. Mean Width\", \"Δ Avg. MWI Score\")\n",
    ")\n",
    "\n",
    "# Coverage bars\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_cov_before,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. Coverage (Before)',\n",
    "    marker_color='rgba(31, 119, 180, 0.6)',\n",
    "    text=[f\"{v:.2f}\" for v in values_cov_before],\n",
    "    textposition='auto'\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_cov_after,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. Coverage (After)',\n",
    "    marker_color='rgba(31, 119, 180, 1.0)',\n",
    "    text=[f\"{v:.2f}\" for v in values_cov_after],\n",
    "    textposition='auto'\n",
    "), row=1, col=1)\n",
    "\n",
    "# Avg Width bars\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_width_before,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. Mean Width (Before)',\n",
    "    marker_color='rgba(44, 160, 44, 0.6)',\n",
    "    text=[f\"{v:.2f}\" for v in values_width_before],\n",
    "    textposition='auto'\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_width_after,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. Mean Width (After)',\n",
    "    marker_color='rgba(44, 160, 44, 1.0)',\n",
    "    text=[f\"{v:.2f}\" for v in values_width_after],\n",
    "    textposition='auto'\n",
    "), row=1, col=2)\n",
    "\n",
    "# Avg MWI score bars\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_mwi_before,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. MWI Score (Before)',\n",
    "    marker_color='rgba(214, 39, 40, 0.6) ',\n",
    "    text=[f\"{v:.2f}\" for v in values_mwi_before],\n",
    "    textposition='auto'\n",
    "), row=1, col=3)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=values_mwi_after,\n",
    "    y=[y_outer, y_inner],\n",
    "    orientation='h',\n",
    "    name='Avg. MWI Score (After)',\n",
    "    marker_color='rgba(214, 39, 40, 1.0) ',\n",
    "    text=[f\"{v:.2f}\" for v in values_mwi_after],\n",
    "    textposition='auto'\n",
    "), row=1, col=3)\n",
    "\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    width=1100,\n",
    "    barmode='group',\n",
    "    showlegend=True,\n",
    "    template='plotly_white',\n",
    "    title_text=f\"Before vs After Comparison by Test Set & Model (Anomaly + Distribution Shift)\"\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='avg(Coverage)', row=1, col=1, tickformat=\".1f\", range=[85,100])\n",
    "fig.update_xaxes(title_text='avg(Mean Width)', row=1, col=2, tickformat=\".1f\", range=[0,0.9])\n",
    "fig.update_xaxes(title_text='avg(MWI Score)', row=1, col=3, tickformat=\".1f\")\n",
    "fig.update_yaxes(showgrid=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e48a04-9fe5-4780-937d-df59657a53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Muted, distinct colors for each std_category\n",
    "palette = [\n",
    "    \"#4C72B0\",  # muted blue\n",
    "    \"#55A868\",  # muted green\n",
    "    \"#C44E52\",  # muted red\n",
    "    \"#8172B3\",  # muted purple\n",
    "    \"#CCB974\",  # muted mustard\n",
    "    \"#64B5CD\"   # muted cyan\n",
    "]\n",
    "\n",
    "x_models = [m.split(\" + \")[0].replace(\": Residual Normalized Score\", \"\") for m in categories_inner]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=3, shared_xaxes=True,\n",
    "    subplot_titles=(\"Avg. Coverage\", \"Avg. Mean Width\", \"Avg. MWI Score\")\n",
    ")\n",
    "\n",
    "# Compute ordering of models based on the first metric (coverage before)\n",
    "first_metric_vals = []\n",
    "\n",
    "for inner in categories_inner:\n",
    "    row = sim_anom_chart_df[\n",
    "        (sim_anom_chart_df['std_category'] == categories_outer[0]) &\n",
    "        (sim_anom_chart_df['model_name'] == inner)\n",
    "    ]\n",
    "    if row.empty:\n",
    "        first_metric_vals.append(float('inf'))\n",
    "    else:\n",
    "        first_metric_vals.append(row['mean_before_coverage'].iloc[0])\n",
    "\n",
    "# Sort categories_inner and x_models by this metric\n",
    "sorted_pairs = sorted(zip(first_metric_vals, categories_inner, x_models), key=lambda x: x[0])\n",
    "_, categories_inner_sorted, x_models_sorted = zip(*sorted_pairs)\n",
    "\n",
    "\n",
    "for idx, outer in enumerate(categories_outer):\n",
    "    color = palette[idx % len(palette)]\n",
    "\n",
    "    cov_before, cov_after = [], []\n",
    "    wid_before, wid_after = [], []\n",
    "    mwi_before, mwi_after = [], []\n",
    "    \n",
    "    for inner in categories_inner_sorted:\n",
    "        row = sim_anom_chart_df[\n",
    "            (sim_anom_chart_df['std_category'] == outer) &\n",
    "            (sim_anom_chart_df['model_name'] == inner)\n",
    "        ]\n",
    "        if row.empty:\n",
    "            cov_before.append(None); cov_after.append(None)\n",
    "            wid_before.append(None); wid_after.append(None)\n",
    "            mwi_before.append(None); mwi_after.append(None)\n",
    "            continue\n",
    "        \n",
    "        cov_before.append(row['mean_before_coverage'].iloc[0])\n",
    "        cov_after.append(row['mean_after_coverage'].iloc[0])\n",
    "        wid_before.append(row['mean_before_avg_width'].iloc[0])\n",
    "        wid_after.append(row['mean_after_avg_width'].iloc[0])\n",
    "        mwi_before.append(row['mean_before_mwi_score'].iloc[0])\n",
    "        mwi_after.append(row['mean_after_mwi_score'].iloc[0])\n",
    "    \n",
    "    # Coverage\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_models_sorted, y=cov_before, mode='lines+markers',\n",
    "        name=f\"{outer} (Before)\", line=dict(color=color, dash='dot')\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_models_sorted, y=cov_after, mode='lines+markers',\n",
    "        name=f\"{outer} (After)\", line=dict(color=color)\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Width\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_models_sorted, y=wid_before, mode='lines+markers',\n",
    "        name=f\"{outer} (Before)\", showlegend=False,\n",
    "        line=dict(color=color, dash='dot')\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_models_sorted, y=wid_after, mode='lines+markers',\n",
    "        name=f\"{outer} (After)\", showlegend=False,\n",
    "        line=dict(color=color)\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    # MWI\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_models_sorted, y=mwi_before, mode='lines+markers',\n",
    "        name=f\"{outer} (Before)\", showlegend=False,\n",
    "        line=dict(color=color, dash='dot')\n",
    "    ), row=1, col=3)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_models_sorted, y=mwi_after, mode='lines+markers',\n",
    "        name=f\"{outer} (After)\", showlegend=False,\n",
    "        line=dict(color=color)\n",
    "    ), row=1, col=3)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=650,\n",
    "    width=1300,\n",
    "    template='plotly_white',\n",
    "    title=\"Anomaly + Distribution Shift: Before vs After Distribution Shift Comparison by STD Category\"\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title='Model', tickangle=30)\n",
    "fig.update_yaxes(showgrid=True)\n",
    "# Add visible left and bottom borders\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor=\"darkgrey\", mirror=False)\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor=\"darkgrey\", mirror=False)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8747a8-8455-47b4-9b84-3f371ced7893",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "- Incorporate error bars when presenting\n",
    "- Only include 2-3 significant figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4b31c4-a6ce-44c9-b8be-3a09b6260478",
   "metadata": {},
   "source": [
    "## Synthetic anomaly results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70903acd-719a-4d31-97d3-a9c9a475ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data(\"Real Distribution Shift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a835801-7c8c-4d1b-8edb-fc2858d84696",
   "metadata": {},
   "source": [
    "### Testing on sample symbol and date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1bd021-1f79-4cc7-a823-596094577097",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data = get_reference_data(symbol=\"BKCC\", start_dt = \"2014-04-03\", end_dt=\"2015-12-09\", mkt_utils=mkt_utils)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665d699-77e1-4e20-a4ad-e101079b79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_query = \"\"\"\n",
    "select t.* \n",
    "from {table} t\n",
    "where test_set = '{test_set}'\n",
    "and symbol = '{symbol}'\n",
    "\"\"\"\n",
    "model_df = pd.read_sql(model_query.format(table=\"argarch_results\", test_set = \"Simulated Anomaly 700\", symbol=\"206838503019\"), conn)\n",
    "#sub_ref_df = ref_data[-len(model_df):].reset_index(drop=True)\n",
    "#model_df_dt = model_df.merge(sub_ref_df[[\"dlycaldt\"]], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debb90d-480a-466f-add3-ef2e6d6ca013",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[model_df[\"model\"] == \"AR(1)-GARCH(1,1)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e1e0c-ead9-4e37-a5a6-ce681cb184bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df_dt[\"anom_flag\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24f762-7779-4b7a-9e8e-f635e0bd638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c0a01-ee6d-42b8-b0b3-22c48f497463",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_anomaly_qry = \"\"\"\n",
    "select *\n",
    "from manual_anomalies\n",
    "where symbol = '{symbol}'\n",
    "\"\"\"\n",
    "real_anom_record = pd.read_sql(real_anomaly_qry.format(symbol=\"BKCC\"), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0b3993-6824-4d04-a22d-65797e6aa2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df_dt.loc[model_df_dt['dlycaldt'].isin(real_anom_record[\"date\"].unique()), 'anom_flag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be221836-87e2-4877-8209-92fe3ec5bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df_dt[model_df_dt['anom_flag'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4ff6a6-2b18-42cc-a616-acc770081fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the index of the row with 1\n",
    "anom_idx = model_df_dt.index[model_df_dt['anom_flag'] == 1][0]\n",
    "\n",
    "# Split into two datasets\n",
    "before = model_df_dt.loc[:anom_idx-1]      # includes the 1\n",
    "after = model_df_dt.loc[anom_idx + 1:]         # rows after the 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f7b07-eaf9-4f4c-88c0-c10ae82e3a59",
   "metadata": {},
   "source": [
    "**Metrics**\n",
    "- Stats before\n",
    "- Stats after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b707a5-5d4d-4a23-9b90-06dd95c89323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_fitting import ModelFitting\n",
    "m_fitting = ModelFitting(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185172f-cc58-428b-aa3f-2333b7ef2a97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_df_dt[~model_df_dt[\"within_CI\"].astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b32345-22c8-42a7-a6d9-88601777a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "~model_df_dt[\"within_CI\"].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d5f897-fd28-4b7f-ba65-6f8c15f32368",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_fitting.get_coverage_stats(before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c3fb7-aa98-433c-ab5e-6b59918812f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_fitting.get_coverage_stats(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415843e7-fd64-48d9-81c3-6a8765d13675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
