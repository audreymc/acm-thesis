{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad620eb6-3fd2-4262-a10d-003455b0053a",
   "metadata": {},
   "source": [
    "# Experiments and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb94dc04-f456-45b6-bd79-900b8c5b1efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "BASE_PATH =  \"/Users/audreymcmillion/Documents/acm-thesis\"\n",
    "sys.path.append(BASE_PATH) \n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "from model_fitting import ModelFitting\n",
    "\n",
    "from ev_scoring import ExtremeValueScoring\n",
    "from market_utils import MarketUtilities\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "\n",
    "ev = ExtremeValueScoring(wrds_username='audreymcmillion')\n",
    "db = ev.wrds_db\n",
    "conn = ev.sqlite_conn\n",
    "mkt_utils = MarketUtilities(wrds_username='audreymcmillion', wrds_db = db, sqlite_conn = conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8fdd4e-fe17-4e31-9f03-40f032d630c4",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c58e8-015d-42e1-87bf-2a6aaf4562d3",
   "metadata": {},
   "source": [
    "- MAPIE Documentation: https://mapie.readthedocs.io/en/stable/theoretical_description_metrics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc52c6-9f13-47b8-b9bb-528e028a334b",
   "metadata": {},
   "source": [
    "## Real Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321aaae7-08b4-4a4e-89df-7f3ab462abba",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{MWI Score} = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i^{\\text{up}} - \\hat{y}_i^{\\text{low}} ) +\\frac{2}{\\alpha} \\sum_{i=1}^n \\max(0, |y_i- \\hat{y}_i^{\\text{boundary}}|)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e055f9-dc8f-4190-a465-a0dd671f47ee",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a74c5-603e-453e-8124-0f374269f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = pd.read_csv(f\"{BASE_PATH}/test_data/covid_results/covid_dist_shift.csv\")\n",
    "covid_shift = covid_data[covid_data.ks_identical == False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497dce36-3067-4331-bde2-70ced2fb2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fe461e-d29b-4908-a4da-eed35bd802ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_data = pd.read_sql(\"\"\"\n",
    "    with valid_symbols as (\n",
    "    \tselect symbol, count(*)\n",
    "    \tfrom argarch_results ar \n",
    "    \twhere test_set = 'Real Anomaly'\n",
    "    \tgroup by symbol\n",
    "    \thaving count(*) >= 100\n",
    "    )\n",
    "    select * \n",
    "    from manual_anomalies ma \n",
    "    where classification = 'Anomaly'\n",
    "    and symbol in (select symbol from valid_symbols)\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da70b59-e0e4-47b6-94f3-3cad643a5278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anomaly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1546d9-f4fc-4608-a9b7-e1b3ff8807c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_shift_query = \"\"\"\n",
    "    SELECT \n",
    "        t.*,\n",
    "        ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY chunk_end_date) AS rn\n",
    "    FROM iterative_ev_kl_5D t\n",
    "    WHERE chunk_start_date > '2000-01-01'\n",
    "    AND kl_divergence > 0.5\n",
    "    AND chunk_end_date > '2020-01-31'\n",
    "  \"\"\"\n",
    "dist_shift_df = pd.read_sql(dist_shift_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b5a9e-4d71-4d7c-882d-14175e69ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist_shift_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fef03e-71c5-4bbd-97d8-6bba799b19d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_shift_df[\"symbol\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa473ed4-d14f-46fa-93cd-2aa67f28ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "interday_query_path = f\"{BASE_PATH}/sql_lib/interday_highlow_query.sql\"\n",
    "with open(interday_query_path, \"r\") as file:\n",
    "    interday_query = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0169af-1602-4096-bb9f-f9a468f96fde",
   "metadata": {},
   "source": [
    "**PARAMETERS:** 350 and 75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b0f861-3940-4a2f-a2ed-86eff88462f5",
   "metadata": {},
   "source": [
    "### AR-GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba08da-951d-4c9f-a4fe-8b957a58c319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "argarch_coverage_lst = []\n",
    "\n",
    "i = 0 \n",
    "for ind, row in tqdm(covid_shift[covid_shift.symbol == 'FTSM'].iterrows()):\n",
    "    symbol, cutoff_dt = row[\"symbol\"], row[\"cutoff_dt\"]\n",
    "    start_dt, end_dt = mkt_utils.get_before_date(cutoff_dt, 350), mkt_utils.get_after_date(cutoff_dt, 75)\n",
    "\n",
    "    # get interday df\n",
    "    interday_df = db.raw_sql(interday_query.format(symbol=symbol, \n",
    "                                     start_dt=start_dt, \n",
    "                                     end_dt=end_dt))\n",
    "\n",
    "    # create object\n",
    "    if i == 0:\n",
    "        model_test =  ModelFitting(data=interday_df)\n",
    "    else:\n",
    "        model_test.reset_data(interday_df)\n",
    "\n",
    "\n",
    "    # fit and forecast an AR(1)-GARCH(1,1) model\n",
    "    argarch_forecast_df = model_test.fit_forecast_ar_garch(window_size=300, garch_p = 1, garch_q = 1)\n",
    "\n",
    "    if argarch_forecast_df.empty:\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    # add columns\n",
    "    argarch_forecast_df[\"symbol\"]   = symbol\n",
    "    argarch_forecast_df[\"start_dt\"] = start_dt\n",
    "    argarch_forecast_df[\"end_dt\"]   = end_dt\n",
    "    argarch_forecast_df[\"model\"]    = \"AR(1)-GARCH(1,1)\"\n",
    "    argarch_forecast_df[\"test_set\"] = \"Real Distibution Shift\"\n",
    "    argarch_forecast_df = argarch_forecast_df.reset_index()\n",
    "    #argarch_forecast_df.to_sql(\"argarch_results\", conn, if_exists='append', index=False)\n",
    "    \n",
    "    # TODO: Save this in database in case we want to run future metrics\n",
    "    argarch_coverage_stats = model_test.get_coverage_stats(argarch_forecast_df)\n",
    "\n",
    "    # append symbol and cutoff date to coverage stats dictionary\n",
    "    argarch_coverage_stats['symbol']     = symbol\n",
    "    argarch_coverage_stats['start_dt']   = start_dt\n",
    "    argarch_coverage_stats['end_dt']     = end_dt\n",
    "    argarch_coverage_stats['test_set']   = \"Real Distribution Shift\"\n",
    "    argarch_coverage_stats['model']      = \"AR(1)-GARCH(1,1)\"\n",
    "    argarch_coverage_stats['base_model'] = None # no base model\n",
    "\n",
    "    # convert to dataframe and add to database\n",
    "    argarch_coverage_stats_df  = pd.DataFrame([argarch_coverage_stats])\n",
    "    #argarch_coverage_stats_df.to_sql(\"model_coverage_stats\", conn, if_exists='append', index=False)\n",
    "    \n",
    "    # append to list\n",
    "    argarch_coverage_lst.append(argarch_coverage_stats)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36385249-0494-43ae-84fd-989f7ee1d353",
   "metadata": {},
   "source": [
    "### Conformal Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7711e515-e383-40c6-82cd-b19bbcc7057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_symbol_conformal(symbol, conformity_score: str, test_set_name: str, start_dt: str, end_dt: str, earliest_dt: str):\n",
    "    # get interday df\n",
    "    interday_df = db.raw_sql(interday_query.format(symbol=symbol, \n",
    "                                     start_dt=earliest_dt, \n",
    "                                     end_dt=end_dt))\n",
    "    interday_df['log_highlow_diff'] = interday_df['log_highlow_diff'].to_numpy(dtype=float)\n",
    "\n",
    "    # create object\n",
    "    model_test =  ModelFitting(data=interday_df)\n",
    "\n",
    "    if conformity_score == \"gamma\":\n",
    "        # fit and forecast Online Conformal and Naive Conformal dataframe\n",
    "        online_df, naive_df = model_test.arma_conformal_forecasting(alpha=0.05, gamma=0.005) # NOTE: Adaptivity parameter of 0.005\n",
    "    else:\n",
    "        # fit and forecast Online Conformal and Naive Conformal dataframe\n",
    "        online_df, naive_df = model_test.argarch_conformal_forecasting(alpha=0.05, gamma=0.005) # NOTE: Adaptivity parameter of 0.005\n",
    "\n",
    "    if online_df.empty or naive_df.empty:\n",
    "        return (None, None), (None, None)\n",
    "\n",
    "    # key-value pairs\n",
    "    online_df[\"symbol\"] = symbol\n",
    "    online_df[\"start_dt\"] = start_dt\n",
    "    online_df[\"end_dt\"] = end_dt\n",
    "    online_df[\"test_set\"] = test_set_name\n",
    "    online_df[\"conformal_mode\"] = \"online\"\n",
    "    \n",
    "    if conformity_score == 'gamma':\n",
    "        online_df['conformity_score'] = 'gamma'\n",
    "        online_df['base_model'] = \"AR(1)\"\n",
    "        online_df[\"forecast_std\"] = None\n",
    "    else:\n",
    "        online_df['conformity_score'] = 'residual_normalized'\n",
    "        online_df['base_model'] = \"AR(1)-GARCH(1,1)\"\n",
    "    \n",
    "    naive_df[\"symbol\"] = symbol\n",
    "    naive_df[\"start_dt\"] = start_dt\n",
    "    naive_df[\"end_dt\"] = end_dt\n",
    "    naive_df[\"test_set\"] = test_set_name\n",
    "    naive_df[\"conformal_mode\"] = \"naive\"\n",
    "\n",
    "    if conformity_score == 'gamma':\n",
    "        naive_df['conformity_score'] = 'gamma'\n",
    "        naive_df['base_model'] = \"AR(1)\"\n",
    "        naive_df[\"forecast_std\"] = None\n",
    "    else:\n",
    "        naive_df['conformity_score'] = 'residual_normalized'\n",
    "        naive_df['base_model'] = \"AR(1)-GARCH(1,1)\"\n",
    "\n",
    "    # get coverage stats\n",
    "    online_coverage_stats = model_test.get_coverage_stats(online_df.copy())\n",
    "\n",
    "    # naive coverage stats - only last x observations\n",
    "    naive_coverage_stats = model_test.get_coverage_stats(naive_df.copy())\n",
    "    \n",
    "    # append symbol and cutoff date to coverage stats dictionary\n",
    "    online_coverage_stats['symbol'] = symbol\n",
    "    online_coverage_stats['start_dt'] = start_dt\n",
    "    online_coverage_stats['end_dt'] = end_dt\n",
    "    online_coverage_stats['test_set'] = test_set_name\n",
    "\n",
    "    if conformity_score == 'gamma':\n",
    "        online_coverage_stats['model'] = \"OC: Gamma Score\"\n",
    "        online_coverage_stats['base_model'] = \"AR(1)\"\n",
    "    else:\n",
    "        online_coverage_stats['model'] = \"OC: Residual Normalized Score\"\n",
    "        online_coverage_stats['base_model'] = \"AR(1)-GARCH(1,1)\"\n",
    "\n",
    "    naive_coverage_stats['symbol'] = symbol\n",
    "    naive_coverage_stats['start_dt'] = start_dt\n",
    "    naive_coverage_stats['end_dt'] = end_dt\n",
    "    naive_coverage_stats['test_set'] = test_set_name\n",
    "    \n",
    "    if conformity_score == 'gamma':\n",
    "        naive_coverage_stats['model'] = \"NC: Gamma Score\"\n",
    "        naive_coverage_stats['base_model'] = \"AR(1)\"\n",
    "    else:\n",
    "        naive_coverage_stats['model'] = \"NC: Residual Normalized Score\"\n",
    "        naive_coverage_stats['base_model'] = \"AR(1)-GARCH(1,1)\"\n",
    "\n",
    "    # save as dataframe\n",
    "    online_coverage_stats_df  = pd.DataFrame([online_coverage_stats])        \n",
    "    naive_conformal_coverage_df  = pd.DataFrame([naive_coverage_stats])\n",
    "\n",
    "    return (online_df.reset_index(), online_coverage_stats_df), (naive_df.reset_index(), naive_conformal_coverage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b7e4f-7cac-4086-9ea3-9ebd372f880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CZR\t2019-11-04\t2020-02-01\n",
    "cutoff_dt = '2020-02-01'\n",
    "start_dt, end_dt = mkt_utils.get_before_date(cutoff_dt, 350), mkt_utils.get_after_date(cutoff_dt, 75)\n",
    "earliest_dt = mkt_utils.get_before_date(cutoff_dt, 450)\n",
    "online_pair, naive_pair = process_symbol_conformal('CZR', conformity_score = 'residual_normalized', test_set_name=\"Real Distribution Shift\", \n",
    "                                                       start_dt=start_dt, end_dt=end_dt, earliest_dt=earliest_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad6a85-667c-4d6c-b22a-edc8b17ecd57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "nyse_cal = mcal.get_calendar(\"NYSE\")\n",
    "\n",
    "def process_row_conformal(row, conformity_score, test_set_name, date_col):\n",
    "    symbol, cutoff_dt = row[\"symbol\"], row[date_col]\n",
    "\n",
    "    mkt_utils_blank = MarketUtilities(wrds_username=None, wrds_db=None, sqlite_conn=None, mcalendar_value=nyse_cal)\n",
    "\n",
    "    start_dt = mkt_utils_blank.get_before_date(cutoff_dt, 350)\n",
    "    end_dt = mkt_utils_blank.get_after_date(cutoff_dt, 75)\n",
    "    earliest_dt = mkt_utils_blank.get_before_date(cutoff_dt, 450)\n",
    "\n",
    "    online_pair, naive_pair = process_symbol_conformal(\n",
    "        symbol,\n",
    "        conformity_score=conformity_score,\n",
    "        test_set_name=test_set_name,\n",
    "        start_dt=start_dt,\n",
    "        end_dt=end_dt,\n",
    "        earliest_dt=earliest_dt\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    if online_pair[0] is not None:\n",
    "        results.append((\"forecast\", online_pair[0]))\n",
    "        results.append((\"coverage\", online_pair[1]))\n",
    "    if naive_pair[0] is not None:\n",
    "        results.append((\"forecast\", naive_pair[0]))\n",
    "        results.append((\"coverage\", naive_pair[1]))\n",
    "\n",
    "    return results\n",
    "\n",
    "start_time = time.time()  # start timer\n",
    "results = Parallel(n_jobs=-1, backend=\"threading\")(\n",
    "    delayed(process_row_conformal)(row, \"residual_normalized\", \"Real Distribution Shift\", date_col=\"cutoff_dt\")\n",
    "    for _, row in tqdm(covid_shift.iterrows(), total=len(covid_shift))\n",
    ")\n",
    "end_time = time.time()  # end timer\n",
    "print(f\"Total elapsed time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Flatten and separate into lists\n",
    "forecast_dfs, coverage_dfs = [], []\n",
    "for res_list in results:\n",
    "    for tag, df in res_list:\n",
    "        if tag == \"forecast\":\n",
    "            forecast_dfs.append(df)\n",
    "        else:\n",
    "            coverage_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20748a10-86a0-4bfe-adcb-2111cf4f9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7528ada9-abee-4040-a56f-970e1069b63a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# forecast_dfs = []\n",
    "# coverage_dfs = []\n",
    "# for ind, row in tqdm(anomaly_data.iterrows()):\n",
    "#     symbol, cutoff_dt = row[\"symbol\"], row[\"date\"]\n",
    "\n",
    "#     print(\"Iteration: \", ind, symbol, cutoff_dt)\n",
    "    \n",
    "#     start_dt, end_dt = mkt_utils.get_before_date(cutoff_dt, 350), mkt_utils.get_after_date(cutoff_dt, 75)\n",
    "#     earliest_dt = mkt_utils.get_before_date(cutoff_dt, 450)\n",
    "#     online_pair, naive_pair = process_symbol_conformal(symbol, conformity_score = 'residual_normalized', test_set_name=\"Real Anomaly\", \n",
    "#                                                        start_dt=start_dt, end_dt=end_dt, earliest_dt=earliest_dt)\n",
    "#     if online_pair[0] is not None:\n",
    "#         forecast_dfs.append(online_pair[0])\n",
    "#         coverage_dfs.append(online_pair[1])\n",
    "\n",
    "#     if naive_pair[0] is not None:\n",
    "#         forecast_dfs.append(naive_pair[0])\n",
    "#         coverage_dfs.append(naive_pair[1])\n",
    "\n",
    "# --- Batch insert after loop ---\n",
    "if forecast_dfs:\n",
    "    all_forecasts = pd.concat(forecast_dfs, ignore_index=True)\n",
    "    all_forecasts[\"symbol\"] = all_forecasts[\"symbol\"].astype(str)\n",
    "    all_forecasts.to_sql(\"conformal_results\", conn, if_exists=\"append\", index=False)\n",
    "\n",
    "if coverage_dfs:\n",
    "    all_coverage = pd.concat(coverage_dfs, ignore_index=True)\n",
    "    all_coverage.to_sql(\"model_coverage_stats\", conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52badbe2-4316-4b63-a833-9d7653a27e57",
   "metadata": {},
   "source": [
    "### DtACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b56db-223f-4c61-927f-c20253d77152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json \n",
    "from DtACI import DtACI\n",
    "import numpy as np\n",
    "\n",
    "def process_symbol_dtaci(symbol, test_set_name: str, start_dt: str, end_dt: str, earliest_dt: str, I: int | None):\n",
    "    # get interday df\n",
    "    interday_df = db.raw_sql(interday_query.format(symbol=symbol, \n",
    "                                     start_dt=earliest_dt,\n",
    "                                     end_dt=end_dt))\n",
    "\n",
    "    # create object\n",
    "    dtaci_obj =  DtACI(data=interday_df)\n",
    "\n",
    "    # fit and forecast Online Conformal and Naive Conformal dataframe\n",
    "    # if I is not None:\n",
    "    #     gamma_df = dtaci_obj.get_dtaci_forecast_df(score_type=\"gamma\", I = I)\n",
    "    # else:\n",
    "    #     gamma_df = dtaci_obj.get_dtaci_forecast_df(score_type=\"gamma\", I=np.inf)\n",
    "        \n",
    "    if I is not None:\n",
    "        resnorm_df = dtaci_obj.get_dtaci_forecast_df(score_type=\"residual_normalized\", eta_adapt=False, I=I)\n",
    "    else:\n",
    "        resnorm_df = dtaci_obj.get_dtaci_forecast_df(score_type=\"residual_normalized\", eta_adapt=False, I=np.inf)\n",
    "\n",
    "    # if gamma_df.empty: #or resnorm_df.empty:\n",
    "    #     return (None, None), (None, None)\n",
    "    if resnorm_df.empty:\n",
    "        return (None, None)\n",
    "\n",
    "    # key-value pairs\n",
    "    # gamma_df[\"symbol\"] = symbol\n",
    "    # gamma_df[\"start_dt\"] = start_dt\n",
    "    # gamma_df[\"end_dt\"] = end_dt\n",
    "    # gamma_df[\"test_set\"] = test_set_name\n",
    "    # gamma_df['conformity_score'] = 'gamma'\n",
    "    # gamma_df['model'] = \"AR(1)-GARCH(1,1)\"\n",
    "\n",
    "    resnorm_df[\"symbol\"] = symbol\n",
    "    resnorm_df[\"start_dt\"] = start_dt\n",
    "    resnorm_df[\"end_dt\"] = end_dt\n",
    "    resnorm_df[\"test_set\"] = test_set_name\n",
    "    resnorm_df['conformity_score'] = \"residual_normalized\"\n",
    "    if I is not None:\n",
    "        resnorm_df['model'] = f\"AR(1)-GARCH(1,1);I={str(I)}\"\n",
    "    else:\n",
    "        resnorm_df['model'] = \"AR(1)-GARCH(1,1)\"\n",
    "\n",
    "    # coverage stat dataframes\n",
    "    # dtaci_gamma_coverage_stats = dtaci_obj.get_coverage_stats(gamma_df, level = 0.95)\n",
    "    dtaci_resnorm_coverage_stats = dtaci_obj.get_coverage_stats(resnorm_df, level = 0.95)\n",
    "        \n",
    "    # append symbol and cutoff date to coverage stats dictionary\n",
    "    # dtaci_gamma_coverage_stats['symbol'] = symbol\n",
    "    # dtaci_gamma_coverage_stats['start_dt'] = start_dt\n",
    "    # dtaci_gamma_coverage_stats['end_dt'] = end_dt\n",
    "    # dtaci_gamma_coverage_stats['test_set'] = test_set_name\n",
    "    # dtaci_gamma_coverage_stats['model'] = \"DtACI: Gamma Score\"\n",
    "    # dtaci_gamma_coverage_stats['base_model'] = \"AR(1)-GARCH(1,1)\"\n",
    "\n",
    "    dtaci_resnorm_coverage_stats['symbol'] = symbol\n",
    "    dtaci_resnorm_coverage_stats['start_dt'] = start_dt\n",
    "    dtaci_resnorm_coverage_stats['end_dt'] = end_dt\n",
    "    dtaci_resnorm_coverage_stats['test_set'] = test_set_name\n",
    "    if I is not None:\n",
    "        dtaci_resnorm_coverage_stats['model'] = f\"DtACI: Residual Normalized Score;I={str(I)}\"\n",
    "    else:\n",
    "        dtaci_resnorm_coverage_stats['model'] = \"DtACI: Residual Normalized Score\"\n",
    "        \n",
    "    dtaci_resnorm_coverage_stats['base_model'] = \"AR(1)-GARCH(1,1)\"\n",
    "\n",
    "    # save as dataframe\n",
    "    # dtaci_gamma_coverage_stats_df  = pd.DataFrame([dtaci_gamma_coverage_stats])        \n",
    "    dtaci_resnorm_coverage_stats_df  = pd.DataFrame([dtaci_resnorm_coverage_stats])\n",
    "\n",
    "    # return (gamma_df.reset_index(), dtaci_gamma_coverage_stats_df)\n",
    "    return (resnorm_df.reset_index(), dtaci_resnorm_coverage_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4dce6-5570-493c-8561-51d57fd6653c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "covid_shift[covid_shift.symbol == 'FTSM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235bf262-22d7-4bec-9af8-bf96e27625eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "forecast_dfs = []\n",
    "coverage_dfs = []\n",
    "for ind, row in tqdm(covid_shift[covid_shift.symbol == 'FTSM'].iterrows()):\n",
    "    symbol, cutoff_dt = row[\"symbol\"], row[\"cutoff_dt\"] # cutoff_dt\n",
    "\n",
    "    print(\"Iteration: \", ind, symbol, cutoff_dt)\n",
    "    \n",
    "    start_dt, end_dt = mkt_utils.get_before_date(cutoff_dt, 350), mkt_utils.get_after_date(cutoff_dt, 75)\n",
    "    earliest_dt = mkt_utils.get_before_date(cutoff_dt, 450)\n",
    "    resnorm_pair = process_symbol_dtaci(symbol, test_set_name=\"Real Distribution Shift\", \n",
    "                                                    start_dt=start_dt, end_dt=end_dt, earliest_dt = earliest_dt, I = None)\n",
    "    # if gamma_pair[0] is not None:\n",
    "    #     forecast_dfs.append(gamma_pair[0])\n",
    "    #     coverage_dfs.append(gamma_pair[1])\n",
    "\n",
    "    if resnorm_pair[0] is not None:\n",
    "        forecast_dfs.append(resnorm_pair[0])\n",
    "        coverage_dfs.append(resnorm_pair[1])\n",
    "\n",
    "# --- Batch insert after loop ---\n",
    "if forecast_dfs:\n",
    "    all_forecasts = pd.concat(forecast_dfs, ignore_index=True)\n",
    "    all_forecasts[\"symbol\"] = all_forecasts[\"symbol\"].astype(str)\n",
    "    all_forecasts = all_forecasts.rename(columns={\"base_model\": \"model\"})\n",
    "    #all_forecasts.to_sql(\"dtaci_results_new\", conn, if_exists=\"append\", index=False)\n",
    "\n",
    "if coverage_dfs:\n",
    "    all_coverage = pd.concat(coverage_dfs, ignore_index=True)\n",
    "    #all_coverage.to_sql(\"model_coverage_stats\", conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0dde36-50ab-4ec9-9276-84a9b65ea2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_dfs[0].to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81503b7-41aa-4c6a-8b2f-efe26e541ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d808b-4449-4bb3-9f18-8e326b546e9f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e2ce86-bed9-4893-a7c2-504478e869e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_query = \"\"\"\n",
    "with symbol_dates as (\n",
    "\tSELECT symbol, start_dt, end_dt \n",
    "\tFROM model_coverage_stats\n",
    "\tGROUP BY symbol, start_dt, end_dt \n",
    "\tHAVING COUNT(DISTINCT model) = (\n",
    "\t    SELECT COUNT(DISTINCT model) \n",
    "\t    FROM model_coverage_stats\n",
    "\t)\n",
    ")\n",
    "\n",
    "select mc.*\n",
    "from symbol_dates sd\n",
    "left join model_coverage_stats mc\n",
    "on (sd.symbol, sd.start_dt, sd.end_dt) = (mc.symbol, mc.start_dt, mc.end_dt)\n",
    "where mc.test_set = 'Real Distribution Shift'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0549c2-2c07-408e-bd68-679a0baa809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_sql(eval_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350cc29c-6388-440a-8c5c-e4224070819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6c5e3-2b34-4bc0-b77f-790674b5d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_evaluation_metrics(eval_df, stat_col, model_col = \"model\", bin_size = 1):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    bin_start, bin_end = eval_df[stat_col].min() - bin_size, eval_df[stat_col].max() + bin_size\n",
    "    bin_settings = dict(start=bin_start, end=bin_end, size=bin_size)  # adjust values to your data range\n",
    "    \n",
    "    # Define each histogram: (dataframe, label, color)\n",
    "    hist_traces = []\n",
    "    colors = ['blue', 'red', 'purple', 'orange', 'green', 'brown', 'cyan', 'grey']\n",
    "    distinct_models = list(eval_df[model_col].unique())\n",
    "\n",
    "    #assert(len(colors) == len(distinct_models))\n",
    "\n",
    "    i = 0\n",
    "    for model in distinct_models:\n",
    "        sub_df = eval_df[eval_df[model_col] == model]\n",
    "        hist_traces.append((sub_df[stat_col], model, colors[i]))\n",
    "        i += 1\n",
    "    \n",
    "    # Add each trace\n",
    "    for data, name, color in hist_traces:\n",
    "        fig.add_trace(go.Histogram(x=data, name=name, marker_color=color, opacity=0.6, xbins=bin_settings))\n",
    "    \n",
    "    # Layout settings\n",
    "    fig.update_layout(\n",
    "        barmode='overlay',  # use 'group' for side-by-side bars\n",
    "        title=f'Comparison of {stat_col} for Different Models',\n",
    "        xaxis_title=f'{stat_col}',\n",
    "        yaxis_title='Frequency',\n",
    "        legend_title='Model Type',\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e6ae78-9d84-47ee-8ce5-9166ecc5beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evaluation_metrics(eval_df, \"coverage\", bin_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85815440-5910-46d2-9983-4d5724181a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evaluation_metrics(eval_df, \"cwc_score\", bin_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d35df-6f0b-4460-bcf2-85f898f9be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evaluation_metrics(eval_df, \"mwi_score\", bin_size=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c4751-7b54-44d0-9fd5-b34e3d72c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evaluation_metrics(eval_df, \"median_width\", bin_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a60fd2-8004-4fba-a3b3-d15a9ad6313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "def mann_whitney_test(eval_df, model1, model2, stat_col, *, model_col = \"model\", alpha=0.1, alternative=\"less\"):\n",
    "    data1 = eval_df[eval_df[model_col] == model1][stat_col]\n",
    "    data2 = eval_df[eval_df[model_col] == model2][stat_col]\n",
    "    statistic, p_value = mannwhitneyu(data1, data2, alternative=alternative)\n",
    "\n",
    "    decision = (\n",
    "        f\"Reject the null hypothesis: Distribution 1 is significantly {alternative} than Distribution 2.\"\n",
    "        if p_value < alpha\n",
    "        else f\"Fail to reject the null hypothesis: No significant evidence that Distribution 1 is {alternative} than Distribution 2.\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"U_statistic\": statistic,\n",
    "        \"p_value\": p_value,\n",
    "        \"alpha\": alpha,\n",
    "        \"decision\": decision\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4fd92-86af-4f94-9b1a-719817c64834",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[\"model\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19ea93-4dd5-4749-9b33-037383c53073",
   "metadata": {},
   "outputs": [],
   "source": [
    "mann_whitney_test(eval_df, 'AR(1)-GARCH(1,1)', 'DtACI: Residual Normalized Score', stat_col = \"coverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe1374e-6f0f-4397-89db-90405f527281",
   "metadata": {},
   "outputs": [],
   "source": [
    "mann_whitney_test(eval_df, 'DtACI: Residual Normalized Score', 'AR(1)-GARCH(1,1)', stat_col = \"median_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04faa32-6610-4214-9f00-9bd3560b54eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mann_whitney_test(eval_df, 'DtACI: Residual Normalized Score', 'AR(1)-GARCH(1,1)', stat_col = \"cwc_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c48f4e1-be23-4e5c-8c1a-579218a48172",
   "metadata": {},
   "outputs": [],
   "source": [
    "mann_whitney_test(eval_df, 'DtACI: Residual Normalized Score', 'AR(1)-GARCH(1,1)', stat_col = \"mwi_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1f3399-2c40-4e5b-838e-31ac2f114238",
   "metadata": {},
   "source": [
    "## Synthetic Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35098462-31bc-40ff-89bd-0a985721b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data_df = pd.read_sql(\"\"\"\n",
    "select * \n",
    "from sim_data_distshift_anom_700 sdds\n",
    "where id = 628432101714\n",
    "and min_std = 6\n",
    "and max_std = 7\n",
    "order by id, t\n",
    "\"\"\", conn)\n",
    "\n",
    "if 'data_anom' not in synth_data_df.columns:\n",
    "    synth_data_df[\"log_highlow_diff\"] = synth_data_df[\"data_ext\"]\n",
    "else:\n",
    "    synth_data_df[\"log_highlow_diff\"] = synth_data_df[\"data_anom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a835d1-9337-40c8-9439-2a99df9c7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data_df[synth_data_df['max_flag_anomaly'] == 1].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abcc5c-50ee-4fc5-99f6-a410d2a6591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_utils.get_after_date(\"1900-01-01\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792445f-f006-47bf-9fc1-8f4dca8c6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data_df[synth_data_df[\"id\"] == 970901018586].iloc[100:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca46fd-b201-4a11-8dc4-d938b7d6837e",
   "metadata": {},
   "source": [
    "### AR-GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7968f059-6373-49e3-b34c-00f438b2c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def process_symbol(symbol, dataset_name, min_std=None, max_std=None):\n",
    "    # dummy dates\n",
    "    start_dt, end_dt = \"1900-01-01\", '1900-08-30'\n",
    "\n",
    "    # pull data\n",
    "    if min_std is None and max_std is None:\n",
    "        interday_df = synth_data_df[synth_data_df[\"id\"] == symbol].iloc[100:].reset_index(drop=True)\n",
    "    else:\n",
    "        interday_df = synth_data_df[(synth_data_df[\"id\"] == symbol) \n",
    "            & (synth_data_df[\"min_std\"] == min_std) & (synth_data_df[\"max_std\"] == max_std)].iloc[100:].reset_index(drop=True)\n",
    "\n",
    "    df_cols = list(interday_df.columns)\n",
    "    if 'min_std' in df_cols and 'max_std' in df_cols:\n",
    "        symbol = str(symbol) + \"|\" + \"std=\" + str(int(min_std)) + \";\" + str(int(max_std))\n",
    "\n",
    "    if interday_df.empty:\n",
    "        return None, None  # skip\n",
    "\n",
    "    # fit AR(1)-GARCH(1,1)\n",
    "    model_test = ModelFitting(data=interday_df)\n",
    "    argarch_forecast_df = model_test.fit_forecast_ar_garch(\n",
    "        window_size=300, garch_p=1, garch_q=1\n",
    "    )\n",
    "\n",
    "    if argarch_forecast_df.empty:\n",
    "        return None, None\n",
    "\n",
    "    # add identifying columns\n",
    "    argarch_forecast_df[\"symbol\"]   = symbol\n",
    "    argarch_forecast_df[\"start_dt\"] = start_dt\n",
    "    argarch_forecast_df[\"end_dt\"]   = end_dt\n",
    "    argarch_forecast_df[\"model\"] = \"AR(1)-GARCH(1,1)\"\n",
    "    argarch_forecast_df[\"test_set\"] = dataset_name\n",
    "\n",
    "    # coverage stats\n",
    "    argarch_coverage_stats = model_test.get_coverage_stats(argarch_forecast_df)\n",
    "    argarch_coverage_stats[\"symbol\"]   = symbol\n",
    "    argarch_coverage_stats[\"start_dt\"] = start_dt\n",
    "    argarch_coverage_stats[\"end_dt\"]   = end_dt\n",
    "    argarch_coverage_stats[\"test_set\"] = dataset_name\n",
    "    argarch_coverage_stats[\"model\"]    = \"AR(1)-GARCH(1,1)\"\n",
    "    argarch_coverage_stats['base_model'] = None\n",
    "    if \"R\" in argarch_coverage_stats:\n",
    "        del argarch_coverage_stats[\"R\"]\n",
    "\n",
    "    argarch_coverage_stats_df = pd.DataFrame([argarch_coverage_stats])\n",
    "\n",
    "    return argarch_forecast_df.reset_index(), argarch_coverage_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f154b43-75f0-46d5-a232-e04e7f4e808b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "results = Parallel(n_jobs=-1)(  # -1 = use all cores\n",
    "    delayed(process_symbol)(sym_id, dataset_name = \"Simulated DistShift+Anom 700\", min_std=min_std, max_std=max_std)\n",
    "    for sym_id, min_std, max_std in (synth_data_df[[\"id\", \"min_std\", \"max_std\"]].drop_duplicates().to_numpy())\n",
    ")\n",
    "\n",
    "forecast_dfs = [f for f, c in results if f is not None]\n",
    "coverage_dfs = [c for f, c in results if c is not None]\n",
    "\n",
    "# --- Batch insert after loop ---\n",
    "if forecast_dfs:\n",
    "    all_forecasts = pd.concat(forecast_dfs, ignore_index=True)\n",
    "    all_forecasts.to_sql(\"argarch_results\", conn, if_exists=\"append\", index=False)\n",
    "\n",
    "if coverage_dfs:\n",
    "    all_coverage = pd.concat(coverage_dfs, ignore_index=True)\n",
    "    all_coverage.to_sql(\"model_coverage_stats\", conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e02676-a750-4637-b115-f87d8316913e",
   "metadata": {},
   "source": [
    "### DtACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b42f4f-b55a-4845-a48e-9179b2a97f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json \n",
    "from DtACI import DtACI\n",
    "\n",
    "def process_symbol_dtaci(symbol, dataset_name, *, min_std=None, max_std=None, I = None):\n",
    "    # dummy dates\n",
    "    start_dt, end_dt = \"1900-01-01\", '1900-08-30'\n",
    "\n",
    "   # pull data\n",
    "    if min_std is None and max_std is None:\n",
    "        interday_df = synth_data_df[synth_data_df[\"id\"] == symbol].reset_index(drop=True)\n",
    "    else:\n",
    "        interday_df = synth_data_df[(synth_data_df[\"id\"] == symbol) \n",
    "            & (synth_data_df[\"min_std\"] == min_std) & (synth_data_df[\"max_std\"] == max_std)].reset_index(drop=True)\n",
    "\n",
    "    if interday_df.empty:\n",
    "        return (None, None), (None, None) # skip\n",
    "        \n",
    "    df_cols = list(interday_df.columns)\n",
    "    if 'min_std' in df_cols and 'max_std' in df_cols:\n",
    "        symbol = str(symbol) + \"|\" + \"std=\" + str(int(min_std)) + \";\" + str(int(max_std))\n",
    "\n",
    "    # create object\n",
    "    if I is not None:\n",
    "        dtaci_obj =  DtACI(data=interday_df)\n",
    "    else:\n",
    "        dtaci_obj =  DtACI(data=interday_df)\n",
    "\n",
    "    # fit and forecast Online Conformal and Naive Conformal dataframe\n",
    "    if I is None:\n",
    "        gamma_df = dtaci_obj.get_dtaci_forecast_df(score_type=\"gamma\", garch_p=1, garch_q=1, lookback=300, burn_ind=100)\n",
    "        resnorm_df = dtaci_obj.get_dtaci_forecast_df(score_type=\"residual_normalized\", lookback=300, burn_ind=100)\n",
    "    else:\n",
    "        resnorm_df = dtaci_obj.get_dtaci_forecast_df(score_type=\"residual_normalized\", lookback=300, burn_ind=100, eta_adapt=False, I=I)\n",
    "\n",
    "    if I is None:\n",
    "        if gamma_df.empty or resnorm_df.empty:\n",
    "            return (None, None), (None, None)\n",
    "    else:\n",
    "        if resnorm_df.empty:\n",
    "            return (None, None), (None, None)\n",
    "\n",
    "    # key-value pairs\n",
    "    if I is None:\n",
    "        gamma_df[\"symbol\"] = symbol\n",
    "        gamma_df[\"start_dt\"] = start_dt\n",
    "        gamma_df[\"end_dt\"] = end_dt\n",
    "        gamma_df[\"test_set\"] = dataset_name\n",
    "        gamma_df['conformity_score'] = 'gamma'\n",
    "        gamma_df[\"model\"] = \"AR(1)\"\n",
    "\n",
    "    resnorm_df[\"symbol\"] = symbol\n",
    "    resnorm_df[\"start_dt\"] = start_dt\n",
    "    resnorm_df[\"end_dt\"] = end_dt\n",
    "    resnorm_df[\"test_set\"] = dataset_name\n",
    "    resnorm_df['conformity_score'] = \"residual_normalized\"\n",
    "    \n",
    "    if I is None:\n",
    "        resnorm_df[\"model\"] = \"AR(1)-GARCH(1,1)\"\n",
    "    else:\n",
    "        resnorm_df[\"model\"] = f\"AR(1)-GARCH(1,1);I={str(I)}\"\n",
    "\n",
    "    # coverage stat dataframes\n",
    "    if I is None:\n",
    "        dtaci_gamma_coverage_stats = dtaci_obj.get_coverage_stats(gamma_df, level = 0.95)\n",
    "        \n",
    "    dtaci_resnorm_coverage_stats = dtaci_obj.get_coverage_stats(resnorm_df, level = 0.95)\n",
    "        \n",
    "    # append symbol and cutoff date to coverage stats dictionary\n",
    "    if I is None:\n",
    "        dtaci_gamma_coverage_stats['symbol'] = symbol\n",
    "        dtaci_gamma_coverage_stats['start_dt'] = start_dt\n",
    "        dtaci_gamma_coverage_stats['end_dt'] = end_dt\n",
    "        dtaci_gamma_coverage_stats['test_set'] = dataset_name\n",
    "        dtaci_gamma_coverage_stats['model'] = \"DtACI: Gamma Score\"\n",
    "        dtaci_gamma_coverage_stats['base_model'] = \"AR(1)\"\n",
    "\n",
    "    dtaci_resnorm_coverage_stats['symbol'] = symbol\n",
    "    dtaci_resnorm_coverage_stats['start_dt'] = start_dt\n",
    "    dtaci_resnorm_coverage_stats['end_dt'] = end_dt\n",
    "    dtaci_resnorm_coverage_stats['test_set'] = dataset_name\n",
    "    \n",
    "    if I is None:\n",
    "        dtaci_resnorm_coverage_stats['model'] = \"DtACI: Residual Normalized Score\"\n",
    "    else:\n",
    "        dtaci_resnorm_coverage_stats['model'] = f\"DtACI: Residual Normalized Score;I={str(I)}\"\n",
    "    \n",
    "    # base model\n",
    "    dtaci_resnorm_coverage_stats['base_model'] = \"AR(1)-GARCH(1,1)\"\n",
    "\n",
    "    if \"R\" in dtaci_resnorm_coverage_stats:\n",
    "        del dtaci_resnorm_coverage_stats[\"R\"]\n",
    "   \n",
    "\n",
    "    # convert to dataframes\n",
    "    if I is None:\n",
    "        if \"R\" in dtaci_gamma_coverage_stats:\n",
    "            del dtaci_gamma_coverage_stats[\"R\"]\n",
    "            \n",
    "        dtaci_gamma_coverage_stats_df = pd.DataFrame([dtaci_gamma_coverage_stats])\n",
    "        \n",
    "    dtaci_resnorm_coverage_stats_df = pd.DataFrame([dtaci_resnorm_coverage_stats])\n",
    "\n",
    "    if I is None:\n",
    "        return (gamma_df.reset_index(), dtaci_gamma_coverage_stats_df), (resnorm_df.reset_index(), dtaci_resnorm_coverage_stats_df)\n",
    "    else:\n",
    "        return (None, None), (resnorm_df.reset_index(), dtaci_resnorm_coverage_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152b09b-65ba-4aec-a28f-71070a8f7a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, a = process_symbol_dtaci(12826756181, dataset_name = \"Simulated Anomaly 700\", min_std=None, max_std=None, I = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b1d87-58c4-4e56-8838-16d9cc720594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d1c3d-4521-454f-8982-8814dec82f56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "results = Parallel(n_jobs=-1)(  # -1 = use all cores\n",
    "    delayed(process_symbol_dtaci)(sym_id, dataset_name = \"Simulated DistShift+Anom 700\", min_std=min_std, max_std=max_std, I = None)\n",
    "    # for sym_id in (list(synth_data_df[\"id\"].unique()))\n",
    "    for sym_id, min_std, max_std in (synth_data_df[[\"id\", \"min_std\", \"max_std\"]].drop_duplicates().to_numpy())\n",
    ")\n",
    "\n",
    "forecast_dfs = [f[0] for f, c in results if f[0] is not None]\n",
    "forecast_dfs += [c[0] for f, c in results if c[0] is not None]\n",
    "coverage_dfs = [f[1] for f, c in results if f[1] is not None]\n",
    "coverage_dfs += [c[1] for f, c in results if c[1] is not None]\n",
    "\n",
    "# --- Batch insert after loop ---\n",
    "if forecast_dfs:\n",
    "    all_forecasts = pd.concat(forecast_dfs, ignore_index=True)\n",
    "    all_forecasts.to_sql(\"dtaci_results_new\", conn, if_exists=\"append\", index=False)\n",
    "\n",
    "if coverage_dfs:\n",
    "    all_coverage = pd.concat(coverage_dfs, ignore_index=True)\n",
    "    all_coverage.to_sql(\"model_coverage_stats\", conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf8d5d-74c4-4bae-a74f-c91ba5820d7a",
   "metadata": {},
   "source": [
    "### Other Conformal Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787ccbf-dab3-43ca-a4c7-541348f6a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_symbol_conformal(symbol, conformity_score: str, dataset_name: str, \n",
    "                             min_std = None, max_std = None, start_dt = \"1900-01-01\", end_dt = \"1900-08-30\"):\n",
    "    # pull data\n",
    "    if min_std is None and max_std is None:\n",
    "        interday_df = synth_data_df[synth_data_df[\"id\"] == symbol].reset_index(drop=True)\n",
    "    else:\n",
    "        interday_df = synth_data_df[(synth_data_df[\"id\"] == symbol) \n",
    "            & (synth_data_df[\"min_std\"] == min_std) & (synth_data_df[\"max_std\"] == max_std)].reset_index(drop=True)\n",
    "\n",
    "    # convert to float\n",
    "    interday_df['log_highlow_diff'] = interday_df['log_highlow_diff'].to_numpy(dtype=float)\n",
    "\n",
    "    symbol = str(symbol)\n",
    "\n",
    "    # create object\n",
    "    model_test =  ModelFitting(data=interday_df)\n",
    "\n",
    "    if conformity_score == \"gamma\":\n",
    "        # fit and forecast Online Conformal and Naive Conformal dataframe\n",
    "        online_df, naive_df = model_test.arma_conformal_forecasting(alpha=0.05, gamma=0.005) # NOTE: Adaptivity parameter of 0.005\n",
    "    else:\n",
    "        # fit and forecast Online Conformal and Naive Conformal dataframe\n",
    "        online_df, naive_df = model_test.argarch_conformal_forecasting(alpha=0.05, gamma=0.005) # NOTE: Adaptivity parameter of 0.005\n",
    "\n",
    "    if online_df.empty or naive_df.empty:\n",
    "        return (None, None), (None, None)\n",
    "\n",
    "    df_cols = list(interday_df.columns)\n",
    "    if 'min_std' in df_cols and 'max_std' in df_cols:\n",
    "        symbol = str(symbol) + \"|\" + \"std=\" + str(int(min_std)) + \";\" + str(int(max_std))\n",
    "\n",
    "    # key-value pairs\n",
    "    online_df[\"symbol\"] = symbol\n",
    "    online_df[\"start_dt\"] = start_dt\n",
    "    online_df[\"end_dt\"] = end_dt\n",
    "    online_df[\"test_set\"] = dataset_name\n",
    "    online_df[\"conformal_mode\"] = \"online\"\n",
    "    \n",
    "    if conformity_score == 'gamma':\n",
    "        online_df['conformity_score'] = 'gamma'\n",
    "        online_df['base_model'] = \"AR(1)\"\n",
    "        online_df[\"forecast_std\"] = None\n",
    "    else:\n",
    "        online_df['conformity_score'] = 'residual_normalized'\n",
    "        online_df['base_model'] = \"AR(1)-GARCH(1,1)\"\n",
    "    \n",
    "    naive_df[\"symbol\"] = symbol\n",
    "    naive_df[\"start_dt\"] = start_dt\n",
    "    naive_df[\"end_dt\"] = end_dt\n",
    "    naive_df[\"test_set\"] = dataset_name\n",
    "    naive_df[\"conformal_mode\"] = \"naive\"\n",
    "\n",
    "    if conformity_score == 'gamma':\n",
    "        naive_df['conformity_score'] = 'gamma'\n",
    "        naive_df['base_model'] = \"AR(1)\"\n",
    "        naive_df[\"forecast_std\"] = None\n",
    "    else:\n",
    "        naive_df['conformity_score'] = 'residual_normalized'\n",
    "        naive_df['base_model'] = \"AR(1)-GARCH(1,1)\"\n",
    "\n",
    "    # get coverage stats\n",
    "    online_coverage_stats = model_test.get_coverage_stats(online_df.copy())\n",
    "    naive_coverage_stats = model_test.get_coverage_stats(naive_df.copy())\n",
    "\n",
    "    if \"R\" in online_coverage_stats:\n",
    "            del online_coverage_stats[\"R\"]\n",
    "    if \"R\" in naive_coverage_stats:\n",
    "            del naive_coverage_stats[\"R\"]\n",
    "    \n",
    "    # append symbol and cutoff date to coverage stats dictionary\n",
    "    online_coverage_stats['symbol'] = symbol\n",
    "    online_coverage_stats['start_dt'] = start_dt\n",
    "    online_coverage_stats['end_dt'] = end_dt\n",
    "    online_coverage_stats['test_set'] = dataset_name\n",
    "\n",
    "    if conformity_score == 'gamma':\n",
    "        online_coverage_stats['model'] = \"OC: Gamma Score\"\n",
    "        online_coverage_stats['base_model'] = \"AR(1)\"\n",
    "    else:\n",
    "        online_coverage_stats['model'] = \"OC: Residual Normalized Score\"\n",
    "        online_coverage_stats['base_model'] = \"AR(1)-GARCH(1,1)\"\n",
    "\n",
    "    naive_coverage_stats['symbol'] = symbol\n",
    "    naive_coverage_stats['start_dt'] = start_dt\n",
    "    naive_coverage_stats['end_dt'] = end_dt\n",
    "    naive_coverage_stats['test_set'] = dataset_name\n",
    "    \n",
    "    if conformity_score == 'gamma':\n",
    "        naive_coverage_stats['model'] = \"NC: Gamma Score\"\n",
    "        naive_coverage_stats['base_model'] = \"AR(1)\"\n",
    "    else:\n",
    "        naive_coverage_stats['model'] = \"NC: Residual Normalized Score\"\n",
    "        naive_coverage_stats['base_model'] = \"AR(1)-GARCH(1,1)\"\n",
    "\n",
    "    # save as dataframe\n",
    "    online_coverage_stats_df  = pd.DataFrame([online_coverage_stats])        \n",
    "    naive_conformal_coverage_df  = pd.DataFrame([naive_coverage_stats])\n",
    "\n",
    "    return (online_df.reset_index(), online_coverage_stats_df), (naive_df.reset_index(), naive_conformal_coverage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef3c6f4-ec89-4077-81d1-d51845551c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "# results = Parallel(n_jobs=-1)(  # -1 = use all cores\n",
    "#     delayed(process_symbol_conformal)(sym_id, \"gamma\")\n",
    "#     for sym_id in list(synth_data_df[\"id\"].unique())\n",
    "# )\n",
    "\n",
    "results = Parallel(n_jobs=-1)(  # -1 = use all cores\n",
    "    delayed(process_symbol_conformal)(sym_id, conformity_score = \"residual_normalized\", dataset_name = 'Simulated DistShift+Anom 700', min_std=min_std, max_std=max_std)\n",
    "    #for sym_id in list(synth_data_df[\"id\"].unique())\n",
    "    for sym_id, min_std, max_std in (synth_data_df[[\"id\", \"min_std\", \"max_std\"]].drop_duplicates().to_numpy())\n",
    ")\n",
    "\n",
    "forecast_dfs = [f[0] for f, c in results if f[0] is not None]\n",
    "forecast_dfs += [c[0] for f, c in results if c[0] is not None]\n",
    "coverage_dfs = [f[1] for f, c in results if f[1] is not None]\n",
    "coverage_dfs += [c[1] for f, c in results if c[1] is not None]\n",
    "\n",
    "# --- Batch insert after loop ---\n",
    "if forecast_dfs:\n",
    "    all_forecasts = pd.concat(forecast_dfs, ignore_index=True)\n",
    "    all_forecasts[\"symbol\"] = all_forecasts[\"symbol\"].astype(str)\n",
    "    all_forecasts.to_sql(\"conformal_results\", conn, if_exists=\"append\", index=False)\n",
    "\n",
    "if coverage_dfs:\n",
    "    all_coverage = pd.concat(coverage_dfs, ignore_index=True)\n",
    "    all_coverage.to_sql(\"model_coverage_stats\", conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb8e7b-6e96-4dd7-b636-f09bc6a5e0b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb258a3-f256-4994-8e4b-2210d86146b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_query = \"\"\"\n",
    "select mc.*\n",
    "from model_coverage_stats mc\n",
    "where mc.test_set = 'Simulated Distribution Shift 700'\n",
    "\"\"\"\n",
    "eval_df = pd.read_sql(eval_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5788ef3-2602-49ae-bdf0-e65cd827833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[[\"model\"]].groupby(\"model\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f98c8a-9bfb-4feb-9b61-de70003ca0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evaluation_metrics(eval_df, \"coverage\", bin_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443690fd-2791-492f-a669-7bda98c9e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evaluation_metrics(eval_df, \"median_width\", bin_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97de876-2df8-4e28-a7b4-f664ba13b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evaluation_metrics(eval_df, \"cwc_score\", bin_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab2b51-bb06-4ce6-a0fd-6bb53cbc89e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evaluation_metrics(eval_df, \"mwi_score\", bin_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ebc264-ddd8-4d42-9adc-aee3f1d5d568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
