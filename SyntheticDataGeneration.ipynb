{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5669e745-b5c6-4c87-b7ae-91319e6e14bf",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b52b8a9-e42a-4756-9871-75ed997b8e3a",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b1e05-ec89-4160-b141-0c7229157990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from ev_scoring import ExtremeValueScoring\n",
    "from market_utils import MarketUtilities\n",
    "from ydata.connectors import GCSConnector\n",
    "from ydata.dataset.filetype import FileType\n",
    "from ydata.metadata import Metadata\n",
    "from ydata.synthesizers.timeseries.model import TimeSeriesSynthesizer\n",
    "from ydata.utils.data_types import VariableType\n",
    "from ydata.utils.formats import read_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a42b8-502a-4ca7-8137-bb167046fa44",
   "metadata": {},
   "source": [
    "## Information/Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4b6afa-b968-4619-b65a-9cd9c478e371",
   "metadata": {},
   "source": [
    "Below are resources for Generative Adversarial networks:\n",
    "- https://github.com/ydataai/ydata-synthetic/blob/master/data/stock_data.csv\n",
    "- https://papers.nips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pd: *Time Series Generative Adversarial Networks*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c85c6-30a6-4bba-af0d-76a243637829",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2942a-9559-425e-970b-0dd6d297fcdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ev = ExtremeValueScoring(wrds_username='audreymcmillion')\n",
    "db = ev.wrds_db\n",
    "conn = ev.sqlite_conn\n",
    "mkt_utils = MarketUtilities(wrds_username='audreymcmillion', wrds_db = db, sqlite_conn = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda0761-7b3a-4029-988b-f18325653efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fa1ff-3f5b-466d-bc34-ef8793ad2135",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ac928-a047-400f-9747-857555a5827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sql_lib/interday_highlow_query.sql\", \"r\") as file:\n",
    "    interday_hl_template = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b4ff0-c44f-4402-9415-f187bf0d6086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a test dataframe using my favorite ticker (CZR)\n",
    "czr_df = mkt_utils.wrds_db.raw_sql(interday_hl_template.format(symbol='CZR', \\\n",
    "                                                                   start_dt='2015-06-01', \\\n",
    "                                                                   end_dt='2020-02-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a9f25-2b8b-4d5d-bd48-e805fea67eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "czr_df['dlyclose'].plot() # plotting the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f750ce15-d24d-4335-b1f6-d703743095d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "czr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7281933-356a-4c48-b513-42c792dae18f",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58429281-0ec0-4499-95b8-c172cb80afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_czr_df = czr_df[['dlycaldt', 'dlyopen', 'dlyclose', 'dlyhigh', 'dlylow', 'dlynumtrd', 'dlyvol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395c851-fd8c-4691-ad0e-1662f5d0c917",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = TimeSeriesSynthesizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a50af-7700-4f40-96e3-9bab783fa15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# czr_df[['dlycaldt', 'dlyopen', 'dlyclose', 'dlyhigh', 'dlylow', 'dlyvol']].to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a287275-b235-40c1-bff1-0e8ecbb2a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata.connectors import LocalConnector\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from ydata import connectors\n",
    "\n",
    "connector = LocalConnector()\n",
    "\n",
    "# Read the data\n",
    "data = connector.read_file('test.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb84bb3-f91c-4bcd-b7c2-267e97a5b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb9077-6837-4661-81c5-43e21402c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata.dataset import Dataset\n",
    "my_data = Dataset(sub_czr_df)\n",
    "\n",
    "dataset_attrs = {\"sortbykey\": \"dlycaldt\"}\n",
    "m = Metadata(my_data, dataset_attrs=dataset_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c8c3a-21a2-4084-830d-d6714139e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.schema\n",
    "# m.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e742f861-7c2b-4d2d-b364-68317e81aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = TimeSeriesSynthesizer()\n",
    "synth.fit(my_data, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab3cd90-e9b7-47c1-8a36-3586dfcae7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_sample = synth.sample(n_entities = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f0ca8-ebde-478d-b12f-86b4e0972025",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5f4f3-25f2-44c5-a733-f111259d418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_czr_df['dlycaldt'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e326b-38c7-4e9d-9eba-e51d1c199e39",
   "metadata": {},
   "source": [
    "## Extreme Value Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb519c0-b3a3-4feb-81a8-48d435fc84ef",
   "metadata": {},
   "source": [
    "Methodology:\n",
    "1. Generate an entire return series using a baseline AR(1)-GARCH(1,1) model.\n",
    "2. Transform the extremes generated via this simplistic model to that from a parameterized generalized extreme value distribution.\n",
    "   - Assumption is that we use the block-over-maxima method to isolate the extremes within these periods.\n",
    "   - A challenge with this method is the IID assumption. Perhaps we can implement some controls that prevent the sampled extreme value from being too far from the prior generated value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c738336e-d3f4-431f-8253-c3dfdc9c879e",
   "metadata": {},
   "source": [
    "### CZR: A Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2723088-7cb6-43d1-8972-1394193f1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sql_lib/interday_highlow_query.sql\", \"r\") as file:\n",
    "    interday_hl_template = file.read()\n",
    "\n",
    "# extract a test dataframe using my favorite ticker (CZR)\n",
    "czr_df = mkt_utils.wrds_db.raw_sql(interday_hl_template.format(symbol='CZR', \\\n",
    "                                                                   start_dt='2015-06-01', \\\n",
    "                                                                   end_dt='2020-02-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e0940c-2ba3-475d-9ed2-b0180f2dd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more \"stable\" time period\n",
    "hl_series = czr_df[(czr_df.dlycaldt >= '2019-03-25') & (czr_df.dlycaldt <= '2020-01-07')][\"log_highlow_diff\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ab827-7507-49af-be45-13ac90b5c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n",
    "import numpy as np\n",
    "am = arch_model(hl_series, mean='ARX', lags=1, vol='GARCH', p=1, q=1, dist='t')\n",
    "res = am.fit(disp='off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93fd81-dfdf-4526-9b26-c08724710bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6358a5c5-2677-4d47-a996-d79bce29e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d31a98-df0d-420e-adb1-d8b58f025960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate data using the parameters from the AR-GARCH model\n",
    "sim_data = am.simulate(\n",
    "    params=res.params, \n",
    "    nobs=400,\n",
    "    initial_value=hl_series.iloc[-1], \n",
    "    x=None,                       \n",
    "    burn=100                      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb27364-47d1-4eec-b566-8c41edbb082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = sim_data.reset_index().rename(columns={\"index\": \"t\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de608e7-62e0-4407-85b9-3116c042bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "czr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c25be-b851-4a90-90d3-a1b7c0d79932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "fig = px.line(czr_df[(czr_df.dlycaldt >= '2019-01-01') & (czr_df.dlycaldt <= '2020-01-07')], x='dlycaldt', y=\"log_highlow_diff\", title=\"Original Diff[Log(High/Low)] Data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63bdf8e-cbd0-4fb7-b00b-5b62cb715c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "fig = px.line(sim_data[:200], x='t', y=\"data\", title=\"AR-GARCH-Generated Synthetic Data\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c79df-0f8b-4033-9401-5d4440bd91fd",
   "metadata": {},
   "source": [
    "**Extreme value injection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff775fe7-0aa9-454a-8025-b6e68382cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyextremes import EVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7330eb40-23bd-49d1-bd70-2efb1d8451f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def flag_max_n(series: pd.Series, n: int) -> pd.Series:\n",
    "    flags = pd.Series(0, index=series.index)\n",
    "    \n",
    "    # Iterate over the series in chunks\n",
    "    for start in range(0, len(series), n):\n",
    "        end = min(start + n, len(series))\n",
    "        chunk = series.iloc[start:end]\n",
    "        \n",
    "        if not chunk.empty:\n",
    "            max_idx = chunk.idxmax()\n",
    "            flags.loc[max_idx] = 1\n",
    "\n",
    "    return flags\n",
    "    \n",
    "sim_data['max_flag'] = flag_max_n(sim_data['data'], n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62aad5b-1b9d-4c33-919a-ffd9518a4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data['max_flag_str'] = sim_data['max_flag'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ec78b-08be-4f1a-9a68-bb0076bdd65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_extremes(sim_data, x, y, color_col):\n",
    "    fig = px.scatter(\n",
    "        sim_data,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        color=color_col,  # Color based on 'flag'\n",
    "        color_discrete_map={'0': 'gray', '1': 'red'},  # Customize colors\n",
    "    )\n",
    "    \n",
    "    # Connect the dots with a line\n",
    "    fig.add_scatter(\n",
    "        x=sim_data[x],\n",
    "        y=sim_data[y],\n",
    "        mode='lines',\n",
    "        line=dict(color='gray'),\n",
    "        showlegend=False,\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "plot_extremes(sim_data, x='t', y='data', color_col='max_flag_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596fd9cc-b4b8-45a3-843c-6b3ed22025ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import genextreme\n",
    "\n",
    "def plot_genextreme_distributions(results, colors=None, labels=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    i = 0\n",
    "    for res in results:\n",
    "        c = res['parameters']['c']\n",
    "        loc = res['parameters'].get('loc', 0)\n",
    "        scale = res['parameters'].get('scale', 1)\n",
    "\n",
    "        # Generate x-values safely within distribution support\n",
    "        x = np.linspace(\n",
    "            genextreme.ppf(0.01, c, loc=loc, scale=scale),\n",
    "            genextreme.ppf(0.9, c, loc=loc, scale=scale),\n",
    "            300\n",
    "        )\n",
    "        y = genextreme.pdf(x, c, loc=loc, scale=scale)\n",
    "\n",
    "        color = colors[i] if colors and i < len(colors) else None\n",
    "        label = labels[i] if labels and i < len(labels) else f'{i}: c={c:.2f}'\n",
    "\n",
    "        plt.plot(x, y, lw=2, color=color, label=label)\n",
    "        i += 1\n",
    "\n",
    "    plt.title('Generalized Extreme Value (GEV) Distributions')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04930f9b-b64a-499f-b387-64a369c8cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference EV distibution:  \n",
    "\n",
    "reference_ev_orig = {'model': 'genextreme',  \n",
    "  'parameters': {'c': 0.5,  \n",
    "   'loc': 1.5,  \n",
    "   'scale': 1}\n",
    "}\n",
    "\n",
    "reference_ev_new = {'model': 'genextreme',  \n",
    "  'parameters': {'c': -1.5,  \n",
    "   'loc': 1,  \n",
    "   'scale': 0.75}\n",
    "}\n",
    "plot_genextreme_distributions([reference_ev_orig, reference_ev_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04da3b8-0086-4bed-8d05-b78f4dc53bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a plot here to compare parameters of distributions -> are they significantly different from eachother?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448da52-611e-4436-9048-60a62ad53bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import genextreme\n",
    "def simple_accept_reject_sample(c, loc, scale, conditional_std, max_deviation = 3, max_tries=100):\n",
    "    valid_samples = np.array([])\n",
    "    threshold = max_deviation * conditional_std\n",
    "    \n",
    "    while len(valid_samples) == 0:\n",
    "        samples = genextreme.rvs(c, loc=loc, scale=scale, size=max_tries)\n",
    "        valid_samples = samples[samples <= threshold]\n",
    "    \n",
    "    return valid_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a64009-0615-4e1f-a40c-a1d9c5613b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_values = []\n",
    "max_orig = len(sim_data) / 2\n",
    "i = 0\n",
    "for ind, row in sim_data.iterrows():\n",
    "    print(\"Iteration:\", i, \"/\", len(sim_data))\n",
    "    time = row['t']\n",
    "    current_val = row['data']\n",
    "    conditional_std = row[\"volatility\"]\n",
    "    print(conditional_std)\n",
    "    max_flag = row[\"max_flag\"]\n",
    "\n",
    "    if max_flag == 1:\n",
    "        if i <= max_orig:\n",
    "            gen_sample = simple_accept_reject_sample(reference_ev_orig['parameters']['c'], \n",
    "                                                     reference_ev_orig['parameters']['loc'], \n",
    "                                                     reference_ev_orig['parameters']['scale'], conditional_std, max_deviation = 3)\n",
    "            new_values.append(gen_sample)\n",
    "        else:\n",
    "           gen_sample = simple_accept_reject_sample(reference_ev_new['parameters']['c'], \n",
    "                                                     reference_ev_new['parameters']['loc'], \n",
    "                                                     reference_ev_new['parameters']['scale'], conditional_std, max_deviation = 3)\n",
    "           new_values.append(gen_sample) \n",
    "    else:\n",
    "        new_values.append(current_val)\n",
    "\n",
    "    i += 1 # increment i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc38b1-6207-4c61-a420-47d59bb32572",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data['data_ext']  = new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e4dc20-ef75-439e-ae69-003c6acf4441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_extremes_compare(sim_data, x, y, y2, color_col):\n",
    "    # First scatter plot with color\n",
    "    fig = px.scatter(\n",
    "        sim_data,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        color=color_col,\n",
    "        color_discrete_map={'0': 'gray', '1': 'red'},\n",
    "    )\n",
    "\n",
    "    # Add line connecting points for `y`\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=sim_data[x],\n",
    "            y=sim_data[y],\n",
    "            mode='lines',\n",
    "            line=dict(color='gray'),\n",
    "            name='original line',\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Second scatter plot for `y2` with color\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=sim_data[x],\n",
    "            y=sim_data[y2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                color=sim_data[color_col].map({'0': 'gray', '1': 'green'})\n",
    "            ),\n",
    "            name='simulated extremes',\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add line for `y2`\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=sim_data[x],\n",
    "            y=sim_data[y2],\n",
    "            mode='lines',\n",
    "            line=dict(color='gray', dash='dot'),\n",
    "            name='simulated line',\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6524de3-8961-4bd1-b17d-4081ea292f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_extremes_compare(sim_data, x='t', y='data', y2= 'data_ext', color_col='max_flag_str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f9ecd-af7e-486c-bbff-5309b9f14edb",
   "metadata": {},
   "source": [
    "**Transform this back to a candlestick-type chart to visualize the feasability of such a series**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7bba57-20f2-42bf-bcc1-67713e77afc7",
   "metadata": {},
   "source": [
    "1. Get a mean value for the log(H/L) ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f2a55-a4b9-44e6-ab6c-76808de5ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "czr_subset = czr_df[(czr_df.dlycaldt >= '2019-03-25') & (czr_df.dlycaldt <= '2020-01-07')].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef079a-55c4-461d-bbea-f8dc5236ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "czr_subset[\"hl_ratio\"] = np.exp(czr_subset[\"log_highlow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b4902-7751-47c5-be7a-4413d8b52ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_mean = czr_subset[\"dlylow\"].mean()\n",
    "high_mean = czr_subset[\"dlyhigh\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0881309b-455b-49ee-b6dd-98d317dfd911",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ratio = round(high_mean,2)/round(low_mean,2) # round to two decimal points to be realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e7c04-12fa-4524-91ef-b8aec640a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ratio # get the inital ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d5791-b50c-4baf-ae33-c8b64afb9490",
   "metadata": {},
   "outputs": [],
   "source": [
    "czr_subset.hl_ratio.mean() # compare this to the true mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755d9a3-b6a4-4a82-ad49-794b9eeadcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "czr_subset.hl_ratio.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c49184-0617-49d3-978d-cff0c6ad2cd3",
   "metadata": {},
   "source": [
    "Process:\n",
    "1. Divide ``log_highlow_diff`` by 100 (since it is scaled by 100) \n",
    "2. Exponentiate ``log_highlow_diff`` to remove the log, this gives us $\\frac{H_{t}/L_{t}}{H_{t-1}/L_{t-1}}$\n",
    "3. Set a $H_{0}/L_{0}$ value and use this to extract the remaining $H/L$ ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676e229c-ea30-46d1-bb9c-bff37125984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d42c4-aec2-42f5-99a4-190225ff1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_srs = np.exp(sim_data.data_ext/100)\n",
    "untransformed_srs = np.exp(sim_data.data/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52400eb-f48e-494c-91ff-c6a982492697",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_srs # value can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc8128-d0f9-4427-a1e8-8275062755f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_series = [float(initial_ratio)]\n",
    "prev_val = float(initial_ratio)\n",
    "for val in untransformed_srs[1:]:\n",
    "    # val = (H_t / L_t)/(H_{t-1} / L_{t-1})\n",
    "    untransformed_val = max(1, float(val) * prev_val)\n",
    "    result_series.append(untransformed_val)\n",
    "\n",
    "    # set prev_val to val\n",
    "    prev_val = untransformed_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d9a909-b122-47dc-a885-c8c137bfe458",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(result_series[:200]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feff9c0-e985-4829-81aa-cec16fdb9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "czr_subset.hl_ratio.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a3d38-4477-4184-a2d7-46dab061e1ee",
   "metadata": {},
   "source": [
    "**Transform the series back to enforce the minimum**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60282c82-6d6c-47ec-91fb-c5a4d2d80e49",
   "metadata": {},
   "source": [
    "**Fit the extreme value distributions iteratively to the simulated data as a quality check**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023a328-1ac8-4777-aab0-e81eb9e021ad",
   "metadata": {},
   "source": [
    "In addition to this simple accept-reject algorithm based on the conditional standard deviation, to improve this algorithm, we should incorporate:\n",
    "- (a) The mean element of the AR(1)-GARCH(1,1) model\n",
    "- (b) Although this is somewhat baked into the GARCH model already, we can control for consecutive time deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e598c-b134-4178-91ef-2e23fee472f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (synthdata)",
   "language": "python",
   "name": "synthdata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
